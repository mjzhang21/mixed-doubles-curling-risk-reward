---
title: "CSAS 2026: Behavior Classes"
author: "Alejandro Haerter"
date: "2026-01-01"
format:
  pdf:
    colorlinks: true
    linkcolor: blue
    number-sections: true
    geometry: margin=1in
    fontsize: 11pt 
---

# Overview

This notebook builds end-level behavior labels from shot-level data. The goal is
to produce a stable, interpretable behavior classification per team per end, and
then compare those behaviors to power play usage. The workflow is:

1. Load `stones_master_1.csv` (one row per shot).
2. Normalize columns and map shot tasks to coarse behavior groups.
3. Aggregate to end-level, with an early/late phase split.
4. Produce rule-based labels (baseline) and cluster-derived labels (exploratory).
5. Validate labels, compare to power play, and check sensitivity.

# Import and Load

We start with the master stone-level dataset. Each row is a shot, and the output
we want is one row per team per end.

```{python}
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.mixture import GaussianMixture
from sklearn.preprocessing import StandardScaler

df = pd.read_csv('../data/stones_master_1.csv')
```

# Normalize Columns

Normalize column names so the notebook works with older or newer versions of the
master file. `powerplay` here is a flag on the end (repeated per stone), and
`has_hammer` is the team identity for the hammer in that end.

```{python}
rename_map = {
    "MatchID": "match_id",
    "EndID": "end_id",
    "TeamID": "team_id",
    "ShotID": "shot_id",
    "Task": "task",
    "PowerPlay": "powerplay",
    "HasHammer_C": "has_hammer",
    "PreEndScoreDiff": "pre_end_score_diff",
}
for old, new in rename_map.items():
    if old in df.columns and new not in df.columns:
        df.rename(columns={old: new}, inplace=True)

df["powerplay"] = df["powerplay"].fillna(0).astype(int)
df["has_hammer"] = df["has_hammer"].fillna(0).astype(int)
```

# Task Groups

Map each task code into a coarse behavior bucket. This is a simplifying assumption,
not a truth claim, and it is used to construct a baseline behavior signal.

```{python}
offensive_tasks = {0, 1, 2, 3, 5, 7}   # draws/guards/raising/rolls
defensive_tasks = {4, 6, 8, 9, 10, 11} # peels/takeouts/clears
neutral_tasks = {13, -1}               # no stats/unknown

df["task_group"] = np.select(
    [
        df["task"].isin(offensive_tasks),
        df["task"].isin(defensive_tasks),
        df["task"].isin(neutral_tasks),
    ],
    ["offensive", "defensive", "neutral"],
    default="neutral",
)

The early/late split is based on mixed doubles rules: the first four shots cannot
be takeouts. We treat those as the "early" phase and the remaining six shots as
"late." This is used to detect probing behavior (early ambiguity with late intent).

early_ids = {7, 8, 9, 16}
late_ids = {17, 18, 19, 20, 21, 22}
df["phase"] = np.where(
    df["shot_id"].isin(early_ids),
    "early",
    np.where(df["shot_id"].isin(late_ids), "late", "other"),
)
```

# End-Level Aggregation (Per Team)

Aggregate to one row per team per end, then compute phase-aware behavior rates.
The key outputs are early/late offensive and defensive rates, plus overall rates.

```{python}
keys = ["match_id", "end_id", "team_id"]

df_phase = df[df["phase"] != "other"].copy()
phase_counts = (
    df_phase.groupby(keys + ["phase", "task_group"])
    .size()
    .reset_index(name="n")
)
phase_counts["col"] = phase_counts["phase"] + "_" + phase_counts["task_group"]
phase_pivot = phase_counts.pivot_table(
    index=keys, columns="col", values="n", fill_value=0, aggfunc="sum"
).reset_index()

for col in [
    "early_offensive", "early_defensive", "early_neutral",
    "late_offensive", "late_defensive", "late_neutral",
]:
    if col not in phase_pivot.columns:
        phase_pivot[col] = 0

phase_pivot["early_total"] = phase_pivot[
    ["early_offensive", "early_defensive", "early_neutral"]
].sum(axis=1)
phase_pivot["late_total"] = phase_pivot[
    ["late_offensive", "late_defensive", "late_neutral"]
].sum(axis=1)

for phase in ["early", "late"]:
    total = phase_pivot[f"{phase}_total"].replace(0, np.nan)
    for label in ["offensive", "defensive", "neutral"]:
        phase_pivot[f"{phase}_{label}_rate"] = (
            phase_pivot[f"{phase}_{label}"] / total
        )

phase_pivot["off_rate"] = (
    (phase_pivot["early_offensive"] + phase_pivot["late_offensive"])
    / (phase_pivot["early_total"] + phase_pivot["late_total"]).replace(0, np.nan)
)
phase_pivot["def_rate"] = (
    (phase_pivot["early_defensive"] + phase_pivot["late_defensive"])
    / (phase_pivot["early_total"] + phase_pivot["late_total"]).replace(0, np.nan)
)
phase_pivot["neu_rate"] = (
    (phase_pivot["early_neutral"] + phase_pivot["late_neutral"])
    / (phase_pivot["early_total"] + phase_pivot["late_total"]).replace(0, np.nan)
)

context = (
    df.groupby(keys, as_index=False)
    .agg(
        powerplay_value=("powerplay", "max"),
        has_hammer=("has_hammer", "max"),
        pre_end_score_diff=("pre_end_score_diff", "first"),
    )
)
context["powerplay_used"] = context["powerplay_value"].fillna(0).astype(int).ne(0)

end_features = phase_pivot.merge(context, on=keys, how="left", validate="one_to_one")
rate_cols = [c for c in end_features.columns if c.endswith("_rate")]
end_features[rate_cols] = end_features[rate_cols].fillna(0)
end_features.head()
```

# Rule-Based Classification (Draft)

Simple thresholds to label end behavior. This uses late-phase intent because
probing is expected early. Adjust thresholds if labels are too imbalanced.

```{python}
OFF_LATE = 0.60
DEF_LATE = 0.60

end_features["behavior"] = np.select(
    [
        end_features["late_offensive_rate"] >= OFF_LATE,
        end_features["late_defensive_rate"] >= DEF_LATE,
    ],
    ["offensive", "defensive"],
    default="probing",
)

end_features["behavior_strength"] = (
    (end_features["late_offensive_rate"] - end_features["late_defensive_rate"]).abs()
)

end_features["behavior"].value_counts()
```

# Quick Sanity Cross-Tab

Check whether behavior distributions shift during power play. This is descriptive,
not causal.

```{python}
pd.crosstab(
    end_features["behavior"],
    end_features["powerplay_used"],
    normalize="columns"
)
```

# Clustering (Exploratory)

Cluster end-level behavior patterns using standardized features. This is an
unsupervised check for natural groupings beyond the rule-based labels.

```{python}
feature_cols = [
    "early_offensive_rate",
    "early_defensive_rate",
    "late_offensive_rate",
    "late_defensive_rate",
    "pre_end_score_diff",
    "powerplay_used",
    "has_hammer",
]

X = end_features[feature_cols].copy()
X["powerplay_used"] = X["powerplay_used"].astype(int)
X["has_hammer"] = X["has_hammer"].astype(int)
X = X.fillna(0)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kmeans = KMeans(n_clusters=3, random_state=42, n_init=25)
end_features["cluster_k3"] = kmeans.fit_predict(X_scaled)

gmm = GaussianMixture(n_components=3, random_state=42)
end_features["cluster_gmm3"] = gmm.fit_predict(X_scaled)

cluster_summary = (
    end_features.groupby("cluster_k3")[feature_cols]
    .mean()
    .sort_index()
)
cluster_counts = end_features["cluster_k3"].value_counts().sort_index()

cluster_summary
```

```{python}
cluster_counts
```

Compare clusters to rule-based labels.

```{python}
pd.crosstab(end_features["behavior"], end_features["cluster_k3"])
```

PCA view of clusters (for visualization only). This is not used for clustering.

```{python}
pca = PCA(n_components=2, random_state=42)
emb = pca.fit_transform(X_scaled)
pca_df = pd.DataFrame(emb, columns=["pc1", "pc2"])
pca_df["cluster"] = end_features["cluster_k3"].values

pca_df.head()
```

# Label Sanity Check

Mean phase rates by rule-based label. Offensive should show higher late-offensive
rate, defensive should show higher late-defensive rate, and probing should be
lower in both.

```{python}
behavior_summary = (
    end_features.groupby("behavior")[
        ["early_offensive_rate", "early_defensive_rate", "late_offensive_rate", "late_defensive_rate"]
    ]
    .mean()
    .sort_index()
)
behavior_summary
```

Sample a few ends per label for manual review. Use this to spot obvious mislabels.

```{python}
sampled = (
    end_features.groupby("behavior", group_keys=False)
    .apply(lambda x: x.sample(min(5, len(x)), random_state=42))
    .reset_index(drop=True)
)
sample_cols = [
    "match_id", "end_id", "team_id", "behavior",
    "powerplay_used", "has_hammer", "pre_end_score_diff",
    "early_offensive_rate", "early_defensive_rate",
    "late_offensive_rate", "late_defensive_rate",
]
sampled[sample_cols]
```

# Cluster Interpretation

Derive a simple label for clusters using late-phase rates. This gives a parallel
labeling system to compare with the rule-based labels.

```{python}
cluster_means = (
    end_features.groupby("cluster_k3")[
        ["early_offensive_rate", "early_defensive_rate", "late_offensive_rate", "late_defensive_rate"]
    ]
    .mean()
)

def label_cluster(row, margin=0.15):
    if row["late_offensive_rate"] >= row["late_defensive_rate"] + margin:
        return "offensive"
    if row["late_defensive_rate"] >= row["late_offensive_rate"] + margin:
        return "defensive"
    return "probing"

cluster_labels = cluster_means.apply(label_cluster, axis=1)
cluster_means.assign(cluster_label=cluster_labels)
```

```{python}
end_features["cluster_label_k3"] = end_features["cluster_k3"].map(cluster_labels)
pd.crosstab(end_features["cluster_label_k3"], end_features["powerplay_used"], normalize="columns")
```

# Power Play Shifts

Compare rule-based labels vs power play.

```{python}
pd.crosstab(end_features["behavior"], end_features["powerplay_used"], normalize="columns")
```

Compare cluster-derived labels vs power play.

```{python}
pd.crosstab(end_features["cluster_label_k3"], end_features["powerplay_used"], normalize="columns")
```

# Sensitivity Checks

How label proportions change as thresholds move. If results swing wildly, the
classification is unstable.

```{python}
threshold_grid = [0.55, 0.60, 0.65]
rows = []
for t in threshold_grid:
    labels = np.select(
        [
            end_features["late_offensive_rate"] >= t,
            end_features["late_defensive_rate"] >= t,
        ],
        ["offensive", "defensive"],
        default="probing",
    )
    counts = pd.Series(labels).value_counts(normalize=True)
    rows.append({
        "threshold": t,
        "offensive_share": counts.get("offensive", 0),
        "defensive_share": counts.get("defensive", 0),
        "probing_share": counts.get("probing", 0),
    })
pd.DataFrame(rows)
```

Check k=4 cluster size balance. If clusters become tiny, stick with k=3.

```{python}
kmeans4 = KMeans(n_clusters=4, random_state=42, n_init=25)
end_features["cluster_k4"] = kmeans4.fit_predict(X_scaled)
end_features["cluster_k4"].value_counts().sort_index()
```
