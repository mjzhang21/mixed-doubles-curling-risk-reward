---
title: "CSAS 2026: End level Exploratory Data Analysis"
author: "Mark Zhang"
date: last-modified
format:
  pdf:
    colorlinks: true
    linkcolor: blue
    number-sections: true
    geometry: margin=1in
    fontsize: 11pt
---

# Overview

In this exploratory notebook, we explore the different win percentages and
counts of different nations. Team strength is a created as a variable to attempt
to create a explanatory feature for analysis. Later, powerplay ends are narrowed
down. We explore if end id or cumulative score difference impacts hammer team
win percentage in powerplay ends. Finally, we observe powerplay seems to
positively impact hammer win percentage and multi-point percentage, with teams
strongly opting to use powerplay when they are up 3 or more points.

# Team Strength

```{python}
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
df = pd.read_csv("../data/end_level.csv")


df['powerplay_value'] = df['powerplay_value'].fillna(0)
df.info()
df.head()
```

Attempt to create team strength metric. The team strength metric would be a
weighted average of hammer efficiency, force efficiency and steal efficiency.

```{python}
# Hammer scores 2+ (Hammer Efficiency numerator)
df['hammer_2plus'] = ((df['score_hammer'] >= 2)).astype(int)

# Force: opponent (hammer) scores 0 or 1
# Includes blanks (0) by design
df['force_success'] = ((df['score_hammer'] <= 1)).astype(int)

# Steal: non-hammer scores at least 1
df['steal_success'] = ((df['score_nonhammer'] >= 1)).astype(int)
HE = (
    df.groupby('hammer_team_id')['hammer_2plus']
      .mean()
      .rename('HE')
)
FE = (
    df.groupby('nonhammer_team_id')['force_success']
      .mean()
      .rename('FE')
)
SE = (
    df.groupby('nonhammer_team_id')['steal_success']
      .mean()
      .rename('SE')
)
efficiency_df = (
    pd.concat([HE, FE, SE], axis=1)
      .reset_index()
      .rename(columns={'index': 'team_id'})
)
efficiency_df['n_hammer_ends'] = (
    df.groupby('hammer_team_id').size()
    .reindex(efficiency_df['team_id'])
    .values
)

efficiency_df['n_nonhammer_ends'] = (
    df.groupby('nonhammer_team_id').size()
    .reindex(efficiency_df['team_id'])
    .values
)

team_noc_map = (
    df[['hammer_team_id','hammer_noc']]
    .drop_duplicates()
    .rename(columns={
        'hammer_team_id': 'team_id',
        'hammer_noc': 'noc'
    })
)

efficiency_df = efficiency_df.merge(team_noc_map, on='team_id', how='left')
efficiency_df['weighted_score'] = (
    0.56*efficiency_df['HE'] +
    0.24*efficiency_df['FE'] +
    0.2*efficiency_df['SE']
)

efficiency_df.sort_values('weighted_score', ascending=False)
```

```{python}
import seaborn as sns
import matplotlib.pyplot as plt

# Sort by weighted_score descending
efficiency_df_sorted = efficiency_df.sort_values('weighted_score', ascending=False)

# Select columns to plot
plot_cols = ['HE', 'FE', 'SE', 'weighted_score']

sns.set(style="whitegrid")
plt.figure(figsize=(12,6))
sns.heatmap(
    efficiency_df_sorted.set_index('noc')[plot_cols],
    annot=True,
    cmap='coolwarm',
    fmt=".2f"
)
plt.title('Team Efficiency Metrics (HE, FE, SE, Weighted Score)')
plt.ylabel('Team')
plt.show()

```

The team strength metric proves to be pretty accurate, as top teams in the World
Mixed Doubles Rankings are also in the top 10 for weighted average of the three
efficiencies.

Next, merge the metrics to the end level data.

```{python}
# -------------------
# Merge hammer team metrics
# -------------------
ends_df = df.merge(
    efficiency_df[['team_id', 'HE', 'FE', 'SE', 'weighted_score']],
    left_on='hammer_team_id',
    right_on='team_id',
    how='left'
).rename(columns={
    'HE': 'hammer_HE',
    'FE': 'hammer_FE',
    'SE': 'hammer_SE',
    'weighted_score': 'hammer_weighted_score'
}).drop(columns='team_id')

# -------------------
# Merge non-hammer team metrics
# -------------------
ends_df = ends_df.merge(
    efficiency_df[['team_id', 'HE', 'FE', 'SE', 'weighted_score']],
    left_on='nonhammer_team_id',
    right_on='team_id',
    how='left'
).rename(columns={
    'HE': 'nonhammer_HE',
    'FE': 'nonhammer_FE',
    'SE': 'nonhammer_SE',
    'weighted_score': 'nonhammer_weighted_score'
}).drop(columns='team_id')

# -------------------
# Compute differences
# -------------------
ends_df['HE_diff'] = ends_df['hammer_HE'] - ends_df['nonhammer_HE']
ends_df['FE_diff'] = ends_df['hammer_FE'] - ends_df['nonhammer_FE']
ends_df['SE_diff'] = ends_df['hammer_SE'] - ends_df['nonhammer_SE']
ends_df['weighted_score_diff'] = ends_df['hammer_weighted_score'] - ends_df['nonhammer_weighted_score']


```

Differences are computed to get relative strength difference.

Now we try to get a better understanding of how tasks impact hammer and
non-hammer scores. For each task plot number of each and mean hammer and
non-hammer score

```{python}
import pandas as pd

tasks = list(range(12))  # 0 to 11

# Collect data in a list
task_data = []

for k in tasks:
    hammer_col = f'hammer_task_{k}'
    nonhammer_col = f'nonhammer_task_{k}'

    hammer_total = ends_df[hammer_col].sum()
    nonhammer_total = ends_df[nonhammer_col].sum()

    hammer_mean = ends_df[hammer_col].mean()
    nonhammer_mean = ends_df[nonhammer_col].mean()

    task_data.append({
        'task': k,
        'hammer_total': hammer_total,
        'nonhammer_total': nonhammer_total,
        'hammer_mean': hammer_mean,
        'nonhammer_mean': nonhammer_mean
    })

# Convert list of dicts to DataFrame
task_counts = pd.DataFrame(task_data)

# Sort by hammer_total for easier visualization
task_counts = task_counts.sort_values(by='hammer_total', ascending=False)

print(task_counts)
```

Draws are the most frequent and contribute the most to scoring as expected. The
raise/tapback is also similar to a guard and it makes sense it also contributes
to scoring for both teams.

To see which features impact hammer win percentage in power play ends, we run a
regularized logistic regression model with hammer score greater than 1 as a
binary outcome variable. We include strength differences between teams, task
differences, cumulative score difference and end id into the model.

```{python}
import pandas as pd
import numpy as np
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegressionCV
from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split

# -------------------
# Sort by match_id and end_id to avoid leakage
# -------------------
ends_df=ends_df[ends_df['powerplay_value']!=0]
ends_df = ends_df.sort_values(['match_id', 'end_id'])

# Compute task_diff features
high_impact_tasks = [0,1,2,3,4,5,6,7,8,9,10,11]
for k in high_impact_tasks:
    ends_df[f'task_diff_{k}'] = ends_df[f'hammer_task_{k}'] - ends_df[f'nonhammer_task_{k}']

# -------------------
# Chronological train-test split by match
# -------------------
matches = ends_df['match_id'].unique()
num_train_matches = int(0.7 * len(matches))
train_matches = matches[:num_train_matches]
test_matches  = matches[num_train_matches:]

train_df = ends_df[ends_df['match_id'].isin(train_matches)]
test_df  = ends_df[ends_df['match_id'].isin(test_matches)]

# -------------------
# Features
# -------------------
numeric_features = ['weighted_score_diff', 'cumulative_score_diff', 'end_id'] + [f'task_diff_{k}' for k in high_impact_tasks]
categorical_features = ['powerplay_value']

X_train = train_df[numeric_features + categorical_features]
y_train = (train_df['score_hammer'] > 1).astype(int)

X_test = test_df[numeric_features + categorical_features]
y_test = (test_df['score_hammer'] > 1).astype(int)

# -------------------
# Preprocessing (no polynomial for now)
# -------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_features),
    ('cat', OneHotEncoder(drop='first'), categorical_features)
])

# -------------------
# Pipeline with ElasticNet Logistic RegressionCV
# -------------------
pipe = Pipeline([
    ('preprocessor', preprocessor),
    ('logit', LogisticRegressionCV(
        Cs = np.logspace(-3,-1, 20),
        cv=5,
        penalty='elasticnet',
        solver='saga',            # required for elasticnet
        l1_ratios=[0.5],          # mix of L1 and L2
        scoring='roc_auc',
        class_weight='balanced',
        max_iter=5000,
        random_state=42,
        refit=True
    ))
])

# -------------------
# Fit model
# -------------------
pipe.fit(X_train, y_train)

# -------------------
# Predictions and evaluation
# -------------------
y_pred = pipe.predict(X_test)
y_prob = pipe.predict_proba(X_test)[:, 1]
logit_cv = pipe.named_steps['logit']

# Best C chosen by cross-validation
best_C = logit_cv.C_[0]
print(f"Best C selected: {best_C}")

print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])
disp.plot(cmap='Blues')
disp.ax_.set_title('Logistic Regression Confusion Matrix')
disp.ax_.set_xlabel('Predicted')
disp.ax_.set_ylabel('Actual')

# ROC AUC
roc_auc = roc_auc_score(y_test, y_prob)
# PR AUC
pr_auc = average_precision_score(y_test, y_prob)
print(f"ROC AUC: {roc_auc:.3f}")
print(f"PR AUC:  {pr_auc:.3f}")

# -------------------
# Feature coefficients
# -------------------
# Numeric feature names
num_features = numeric_features
# Categorical feature names after one-hot
cat_feature_names = pipe.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)
all_features = list(num_features) + list(cat_feature_names)

coef_df = pd.Series(pipe.named_steps['logit'].coef_[0], index=all_features)
coef_df_sorted = coef_df.reindex(coef_df.abs().sort_values(ascending=False).index)

print("Top features by absolute coefficient:")
print(coef_df_sorted.head(20))

# -------------------
# Optional: add polynomial features back
# -------------------
# Uncomment if needed
# poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)
# preprocessor = ColumnTransformer(transformers=[
#     ('num', Pipeline([
#         ('poly', poly),
#         ('scaler', StandardScaler())
#     ]), numeric_features),
#     ('cat', OneHotEncoder(drop='first'), categorical_features)
# ])

```

The model is decently predictive with a weighted avg f1 score of 0.65. Weighted
Score difference is the top contributor to winning as the hammer team. This
makes sense because if the hammer team is up more in the score they have a
higher chance of winning. Other predictors are relatively difficult to
interpret, as task differences are not the most reliable since some shots are
much more common than others.

# Exploration

## Powerplay ends

Now we explore specifically the powerplay ends and how they compare to normal
ends. We first see basic counts of how many ends each nation plays.

```{python}
import pandas as pd
import matplotlib.pyplot as plt

df_pp = ends_df[ends_df['powerplay_value'] != 0].copy()
df_pp['hammer_win'] = (df_pp['score_hammer'] > df_pp['score_nonhammer']).astype(int)
df_pp['nonhammer_win'] = (df_pp['score_nonhammer'] > df_pp['score_hammer']).astype(int)
# Count hammer ends
hammer_counts = df_pp['hammer_noc'].value_counts()

# Count non-hammer ends
nonhammer_counts = df_pp['nonhammer_noc'].value_counts()

# Combine totals
total_ends = hammer_counts.add(nonhammer_counts, fill_value=0).sort_values(ascending=True)  # ascending for horizontal plot
plt.figure(figsize=(12,8))
plt.barh(total_ends.index, total_ends.values, color='skyblue')
plt.xlabel('Number of Ends Played')
plt.ylabel('Nation')
plt.title('Number of Ends Played by Each Nation')
plt.tight_layout()
plt.show()

end_counts_df = pd.DataFrame({
    'Hammer': hammer_counts,
    'Non-Hammer': nonhammer_counts
}).fillna(0)

end_counts_df.sort_values('Hammer', inplace=True)
end_counts_df.plot(kind='barh', figsize=(12,8), color=['skyblue','orange'])
plt.xlabel('Number of Ends Played')
plt.ylabel('Nation')
plt.title('Hammer vs Non-Hammer Ends by Nation')
plt.tight_layout()
plt.show()


```

There are several countries with limited powerplay experience in the mixed
doubles and olympic championships. These may be ruled out in possible further
analysis.

We graph non-hammer and hammer-win percentage to see if there are significant
differences between nations

```{python}
# hammer & non-hammer win percentage
hammer_win_pct = (
    df_pp.groupby('hammer_noc')['hammer_win']
    .mean()
    .mul(100)
    .round(2)
)

nonhammer_win_pct = (
    df_pp.groupby('nonhammer_noc')['nonhammer_win']
    .mean()
    .mul(100)
    .round(2)
)


win_df = pd.DataFrame({
    'Hammer': hammer_win_pct,
    'Non-Hammer': nonhammer_win_pct
})

# Sort by Hammer first, then Non-Hammer
win_df_sorted = win_df.sort_values(by=['Hammer', 'Non-Hammer'], ascending=True)  # ascending for horizontal bars

# Horizontal bar chart
win_df_sorted.plot(kind='barh', figsize=(12,8), color=['skyblue','orange'])

plt.xlabel('Win Percentage (%)')
plt.ylabel('Nation')
plt.title('Hammer vs Non-Hammer Win Percentage by Nation (Power Play Ends)')
plt.xlim(0, 100)  # horizontal axis
plt.tight_layout()
plt.show()

```

Results may be misleading due to small sample sizes, Teams have varying win
percentages when they are the hammer or non-hammer team.

Next, we analyze how cumulative score difference leading up to an end impacts
win percentage.

```{python}
import matplotlib.pyplot as plt
import pandas as pd

# Already have bins defined
bins = [-float('inf'), -3, -1, 0, 5, 10, float('inf')]
labels = ['<= -3', '-2 to -1', '0', '1 to 5', '6 to 10', '>10']
df_pp['score_diff_bin'] = pd.cut(df_pp['cumulative_score_diff'], bins=bins, labels=labels)

# Calculate win percentages
hammer_win_by_bin = df_pp.groupby('score_diff_bin')['hammer_win'].mean().mul(100).round(2)
nonhammer_win_by_bin = df_pp.groupby('score_diff_bin')['nonhammer_win'].mean().mul(100).round(2)

# Count number of ends per bin
ends_per_bin = df_pp['score_diff_bin'].value_counts().reindex(labels)

# Combine into a DataFrame for plotting
win_by_bin = pd.DataFrame({
    'Hammer': hammer_win_by_bin,
    'Non-Hammer': nonhammer_win_by_bin
})

# Plot
ax = win_by_bin.plot(kind='bar', figsize=(10,6), color=['skyblue','orange'])
plt.ylabel('Win Percentage (%)')
plt.xlabel('Cumulative Score Difference Bin')
plt.title('Hammer vs Non-Hammer Win Percentage by Score Difference (Powerplay Ends)')
plt.ylim(0, 100)

# Annotate number of ends on top of bars
for i, label in enumerate(labels):
    hammer_val = hammer_win_by_bin[label]
    nonhammer_val = nonhammer_win_by_bin[label]
    n_ends = ends_per_bin[label]
    ax.text(i, max(hammer_val, nonhammer_val)+2, f'n={n_ends}', ha='center', fontsize=10)

plt.tight_layout()
plt.show()

```

In all score difference bins, hammer and non hammer win percentage are similar.
However, a majority of the time, powerplay is used when the hammer team is up
1-5 or 6-10 points over the non-hammer team.

To see how end_id impacts hammer and non-hammer win percentage we draw a
histogram.

```{python}
import matplotlib.pyplot as plt
import pandas as pd

# Calculate win percentages
hammer_win_by_end = df_pp.groupby('end_id')['hammer_win'].mean().mul(100).round(2)
nonhammer_win_by_end = df_pp.groupby('end_id')['nonhammer_win'].mean().mul(100).round(2)

# Count number of ends per end_id
ends_per_end = df_pp['end_id'].value_counts().sort_index()

# Combine into DataFrame
win_by_end = pd.DataFrame({
    'Hammer': hammer_win_by_end,
    'Non-Hammer': nonhammer_win_by_end
})

# Plot
ax = win_by_end.plot(kind='bar', figsize=(12,6), color=['skyblue','orange'])
plt.ylabel('Win Percentage (%)')
plt.xlabel('End ID')
plt.title('Hammer vs Non-Hammer Win Percentage by End (Powerplay Ends)')
plt.ylim(0, 100)

# Annotate number of ends on top of bars
for i, end in enumerate(win_by_end.index):
    n_ends = ends_per_end[end]
    hammer_val = hammer_win_by_end[end]
    nonhammer_val = nonhammer_win_by_end[end]
    ax.text(i, max(hammer_val, nonhammer_val)+2, f'n={n_ends}', ha='center', fontsize=10)

plt.tight_layout()
plt.show()

```

Powerplay is used mostly in end 6 and 7, showing small increases in hammer score
and decreases in non-hammer score. Whether this is due to sample size is
unclear.

Finally, lets make a crosstable of score difference, powerplay status, and
hammer scoring 2 or more percentage to what factors may impact the hammer team
scoring multi-point ends.

```{python}
# Add hammer_2plus flag and Powerplay_Status to full df
df['hammer_2plus'] = (df['score_hammer'] >= 2).astype(int)
df['Powerplay_Status'] = df['powerplay_value'].apply(lambda x: 'Powerplay' if x != 0 else 'No Powerplay')

# Filter to ends 6 and 7
df_subset = df.copy()

# Apply bins to df_subset
bins = [-float('inf'), -2, 0, 2, float('inf')]
labels = [
    'Behind (≤ -2)',
    'Tied or Down 1',
    'Up 1–2',
    'Up ≥ 3'
]

df_subset['score_diff_bin'] = pd.cut(
    df_subset['cumulative_score_diff'],
    bins=bins,
    labels=labels
)

# Aggregate hammer 2+ %
win_stats = (
    df_subset.groupby(['score_diff_bin', 'Powerplay_Status'])
    .agg(
        hammer_2plus_pct=('hammer_2plus', lambda x: round(x.mean()*100,2)),
        n_ends=('hammer_2plus', 'count')
    )
    .reset_index()
)

win_stats_sorted = win_stats.sort_values(by='hammer_2plus_pct', ascending=False)
win_stats_sorted

```

Powerplay clearly increases hammer 2+ percentage. The percentage increases as
the hammer team is leading more. Teams overwhelmingly use powerplay when they
are up 3 or more points over the non0hammer team. Limited data exists when the
hammer team uses powerplay in closer score situations.
