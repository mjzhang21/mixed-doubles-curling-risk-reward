
```{python}
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
df = pd.read_csv("../data/end_level.csv")


df['powerplay_value'] = df['powerplay_value'].fillna(0)
df.info()
df.head()
```



```{python}
# Hammer scores 2+ (Hammer Efficiency numerator)
df['hammer_2plus'] = ((df['score_hammer'] >= 2)).astype(int)

# Force: opponent (hammer) scores 0 or 1
# Includes blanks (0) by design
df['force_success'] = ((df['score_hammer'] <= 1)).astype(int)

# Steal: non-hammer scores at least 1
df['steal_success'] = ((df['score_nonhammer'] >= 1)).astype(int)
HE = (
    df.groupby('hammer_team_id')['hammer_2plus']
      .mean()
      .rename('HE')
)
FE = (
    df.groupby('nonhammer_team_id')['force_success']
      .mean()
      .rename('FE')
)
SE = (
    df.groupby('nonhammer_team_id')['steal_success']
      .mean()
      .rename('SE')
)
efficiency_df = (
    pd.concat([HE, FE, SE], axis=1)
      .reset_index()
      .rename(columns={'index': 'team_id'})
)
efficiency_df['n_hammer_ends'] = (
    df.groupby('hammer_team_id').size()
    .reindex(efficiency_df['team_id'])
    .values
)

efficiency_df['n_nonhammer_ends'] = (
    df.groupby('nonhammer_team_id').size()
    .reindex(efficiency_df['team_id'])
    .values
)

team_noc_map = (
    df[['hammer_team_id','hammer_noc']]
    .drop_duplicates()
    .rename(columns={
        'hammer_team_id': 'team_id',
        'hammer_noc': 'noc'
    })
)

efficiency_df = efficiency_df.merge(team_noc_map, on='team_id', how='left')
efficiency_df['weighted_score'] = (
    0.56*efficiency_df['HE'] +
    0.24*efficiency_df['FE'] +
    0.2*efficiency_df['SE']
)

efficiency_df.sort_values('weighted_score', ascending=False)
```

```{python}
import seaborn as sns
import matplotlib.pyplot as plt

# Sort by weighted_score descending
efficiency_df_sorted = efficiency_df.sort_values('weighted_score', ascending=False)

# Select columns to plot
plot_cols = ['HE', 'FE', 'SE', 'weighted_score']

sns.set(style="whitegrid")
plt.figure(figsize=(12,6))
sns.heatmap(
    efficiency_df_sorted.set_index('noc')[plot_cols],
    annot=True,
    cmap='coolwarm',
    fmt=".2f"
)
plt.title('Team Efficiency Metrics (HE, FE, SE, Weighted Score)')
plt.ylabel('Team')
plt.show()

```
```{python}
# -------------------
# Merge hammer team metrics
# -------------------
ends_df = df.merge(
    efficiency_df[['team_id', 'HE', 'FE', 'SE', 'weighted_score']],
    left_on='hammer_team_id',
    right_on='team_id',
    how='left'
).rename(columns={
    'HE': 'hammer_HE',
    'FE': 'hammer_FE',
    'SE': 'hammer_SE',
    'weighted_score': 'hammer_weighted_score'
}).drop(columns='team_id')

# -------------------
# Merge non-hammer team metrics
# -------------------
ends_df = ends_df.merge(
    efficiency_df[['team_id', 'HE', 'FE', 'SE', 'weighted_score']],
    left_on='nonhammer_team_id',
    right_on='team_id',
    how='left'
).rename(columns={
    'HE': 'nonhammer_HE',
    'FE': 'nonhammer_FE',
    'SE': 'nonhammer_SE',
    'weighted_score': 'nonhammer_weighted_score'
}).drop(columns='team_id')

# -------------------
# Compute differences
# -------------------
ends_df['HE_diff'] = ends_df['hammer_HE'] - ends_df['nonhammer_HE']
ends_df['FE_diff'] = ends_df['hammer_FE'] - ends_df['nonhammer_FE']
ends_df['SE_diff'] = ends_df['hammer_SE'] - ends_df['nonhammer_SE']
ends_df['weighted_score_diff'] = ends_df['hammer_weighted_score'] - ends_df['nonhammer_weighted_score']


```
```{python}
import pandas as pd

tasks = list(range(12))  # 0 to 11

# Collect data in a list
task_data = []

for k in tasks:
    hammer_col = f'hammer_task_{k}'
    nonhammer_col = f'nonhammer_task_{k}'
    
    hammer_total = ends_df[hammer_col].sum()
    nonhammer_total = ends_df[nonhammer_col].sum()
    
    hammer_mean = ends_df[hammer_col].mean()
    nonhammer_mean = ends_df[nonhammer_col].mean()
    
    task_data.append({
        'task': k,
        'hammer_total': hammer_total,
        'nonhammer_total': nonhammer_total,
        'hammer_mean': hammer_mean,
        'nonhammer_mean': nonhammer_mean
    })

# Convert list of dicts to DataFrame
task_counts = pd.DataFrame(task_data)

# Sort by hammer_total for easier visualization
task_counts = task_counts.sort_values(by='hammer_total', ascending=False)

print(task_counts)
```
```{python}
import pandas as pd
import numpy as np
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegressionCV
from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split

# -------------------
# Sort by match_id and end_id to avoid leakage
# -------------------
ends_df=ends_df[ends_df['powerplay_value']!=0]
ends_df = ends_df.sort_values(['match_id', 'end_id'])

# Compute task_diff features
high_impact_tasks = [0,1,2,3,4,5,6,7,8,9,10,11]
for k in high_impact_tasks:
    ends_df[f'task_diff_{k}'] = ends_df[f'hammer_task_{k}'] - ends_df[f'nonhammer_task_{k}']

# -------------------
# Chronological train-test split by match
# -------------------
matches = ends_df['match_id'].unique()
num_train_matches = int(0.7 * len(matches))
train_matches = matches[:num_train_matches]
test_matches  = matches[num_train_matches:]

train_df = ends_df[ends_df['match_id'].isin(train_matches)]
test_df  = ends_df[ends_df['match_id'].isin(test_matches)]

# -------------------
# Features
# -------------------
numeric_features = ['weighted_score_diff', 'cumulative_score_diff', 'end_id'] + [f'task_diff_{k}' for k in high_impact_tasks]
categorical_features = ['powerplay_value']

X_train = train_df[numeric_features + categorical_features]
y_train = (train_df['score_hammer'] > 1).astype(int)

X_test = test_df[numeric_features + categorical_features]
y_test = (test_df['score_hammer'] > 1).astype(int)

# -------------------
# Preprocessing (no polynomial for now)
# -------------------
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), numeric_features),
    ('cat', OneHotEncoder(drop='first'), categorical_features)
])

# -------------------
# Pipeline with ElasticNet Logistic RegressionCV
# -------------------
pipe = Pipeline([
    ('preprocessor', preprocessor),
    ('logit', LogisticRegressionCV(
        Cs = np.logspace(-3,-1, 20),
        cv=5,
        penalty='elasticnet',
        solver='saga',            # required for elasticnet
        l1_ratios=[0.5],          # mix of L1 and L2
        scoring='roc_auc',
        class_weight='balanced',
        max_iter=5000,
        random_state=42,
        refit=True
    ))
])

# -------------------
# Fit model
# -------------------
pipe.fit(X_train, y_train)

# -------------------
# Predictions and evaluation
# -------------------
y_pred = pipe.predict(X_test)
y_prob = pipe.predict_proba(X_test)[:, 1]
logit_cv = pipe.named_steps['logit']

# Best C chosen by cross-validation
best_C = logit_cv.C_[0]
print(f"Best C selected: {best_C}")

print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])
disp.plot(cmap='Blues')
disp.ax_.set_title('Logistic Regression Confusion Matrix')
disp.ax_.set_xlabel('Predicted')
disp.ax_.set_ylabel('Actual')

# ROC AUC
roc_auc = roc_auc_score(y_test, y_prob)
# PR AUC
pr_auc = average_precision_score(y_test, y_prob)
print(f"ROC AUC: {roc_auc:.3f}")
print(f"PR AUC:  {pr_auc:.3f}")

# -------------------
# Feature coefficients
# -------------------
# Numeric feature names
num_features = numeric_features
# Categorical feature names after one-hot
cat_feature_names = pipe.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)
all_features = list(num_features) + list(cat_feature_names)

coef_df = pd.Series(pipe.named_steps['logit'].coef_[0], index=all_features)
coef_df_sorted = coef_df.reindex(coef_df.abs().sort_values(ascending=False).index)

print("Top features by absolute coefficient:")
print(coef_df_sorted.head(20))

# -------------------
# Optional: add polynomial features back
# -------------------
# Uncomment if needed
# poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)
# preprocessor = ColumnTransformer(transformers=[
#     ('num', Pipeline([
#         ('poly', poly),
#         ('scaler', StandardScaler())
#     ]), numeric_features),
#     ('cat', OneHotEncoder(drop='first'), categorical_features)
# ])

```


# Exploration


## Powerplay ends



```{python}
import pandas as pd
import matplotlib.pyplot as plt

# Count hammer ends
hammer_counts = df_pp['hammer_noc'].value_counts()

# Count non-hammer ends
nonhammer_counts = df_pp['nonhammer_noc'].value_counts()

# Combine totals
total_ends = hammer_counts.add(nonhammer_counts, fill_value=0).sort_values(ascending=True)  # ascending for horizontal plot
plt.figure(figsize=(12,8))
plt.barh(total_ends.index, total_ends.values, color='skyblue')
plt.xlabel('Number of Ends Played')
plt.ylabel('Nation')
plt.title('Number of Ends Played by Each Nation')
plt.tight_layout()
plt.show()

end_counts_df = pd.DataFrame({
    'Hammer': hammer_counts,
    'Non-Hammer': nonhammer_counts
}).fillna(0)

end_counts_df.sort_values('Hammer', inplace=True)
end_counts_df.plot(kind='barh', figsize=(12,8), color=['skyblue','orange'])
plt.xlabel('Number of Ends Played')
plt.ylabel('Nation')
plt.title('Hammer vs Non-Hammer Ends by Nation')
plt.tight_layout()
plt.show()


```
```{python}
# hammer & non-hammer win percentage
hammer_win_pct = df_pp.groupby('hammer_noc')['hammer_win'].mean().mul(100).round(2)
nonhammer_win_pct = df_pp.groupby('nonhammer_noc')['nonhammer_win'].mean().mul(100).round(2)

win_df = pd.DataFrame({
    'Hammer': hammer_win_pct,
    'Non-Hammer': nonhammer_win_pct
})

# Sort by Hammer first, then Non-Hammer
win_df_sorted = win_df.sort_values(by=['Hammer', 'Non-Hammer'], ascending=True)  # ascending for horizontal bars

# Horizontal bar chart
win_df_sorted.plot(kind='barh', figsize=(12,8), color=['skyblue','orange'])

plt.xlabel('Win Percentage (%)')
plt.ylabel('Nation')
plt.title('Hammer vs Non-Hammer Win Percentage by Nation (Power Play Ends)')
plt.xlim(0, 100)  # horizontal axis
plt.tight_layout()
plt.show()

```
```{python}
# Calculate average win % for each nation
avg_win_df = win_df.mean(axis=1).sort_values(ascending=True)  # ascending so highest at top

# Plot horizontal bar chart
plt.figure(figsize=(12,8))
plt.barh(avg_win_df.index, avg_win_df.values, color='skyblue')
plt.xlabel('Average Win Percentage (%)')
plt.ylabel('Nation')
plt.title('Average Win Percentage by Nation (Power Play Ends)')
plt.xlim(0, 100)  # horizontal axis limit
plt.tight_layout()
plt.show()


```



```{python}
import matplotlib.pyplot as plt
import pandas as pd

# Already have bins defined
bins = [-float('inf'), -3, -1, 0, 5, 10, float('inf')]
labels = ['<= -3', '-2 to -1', '0', '1 to 5', '6 to 10', '>10']
df_pp['score_diff_bin'] = pd.cut(df_pp['cumulative_score_diff'], bins=bins, labels=labels)

# Calculate win percentages
hammer_win_by_bin = df_pp.groupby('score_diff_bin')['hammer_win'].mean().mul(100).round(2)
nonhammer_win_by_bin = df_pp.groupby('score_diff_bin')['nonhammer_win'].mean().mul(100).round(2)

# Count number of ends per bin
ends_per_bin = df_pp['score_diff_bin'].value_counts().reindex(labels)

# Combine into a DataFrame for plotting
win_by_bin = pd.DataFrame({
    'Hammer': hammer_win_by_bin,
    'Non-Hammer': nonhammer_win_by_bin
})

# Plot
ax = win_by_bin.plot(kind='bar', figsize=(10,6), color=['skyblue','orange'])
plt.ylabel('Win Percentage (%)')
plt.xlabel('Cumulative Score Difference Bin')
plt.title('Hammer vs Non-Hammer Win Percentage by Score Difference (Powerplay Ends)')
plt.ylim(0, 100)

# Annotate number of ends on top of bars
for i, label in enumerate(labels):
    hammer_val = hammer_win_by_bin[label]
    nonhammer_val = nonhammer_win_by_bin[label]
    n_ends = ends_per_bin[label]
    ax.text(i, max(hammer_val, nonhammer_val)+2, f'n={n_ends}', ha='center', fontsize=10)

plt.tight_layout()
plt.show()

```


```{python}
import matplotlib.pyplot as plt
import pandas as pd

# Calculate win percentages
hammer_win_by_end = df_pp.groupby('end_id')['hammer_win'].mean().mul(100).round(2)
nonhammer_win_by_end = df_pp.groupby('end_id')['nonhammer_win'].mean().mul(100).round(2)

# Count number of ends per end_id
ends_per_end = df_pp['end_id'].value_counts().sort_index()

# Combine into DataFrame
win_by_end = pd.DataFrame({
    'Hammer': hammer_win_by_end,
    'Non-Hammer': nonhammer_win_by_end
})

# Plot
ax = win_by_end.plot(kind='bar', figsize=(12,6), color=['skyblue','orange'])
plt.ylabel('Win Percentage (%)')
plt.xlabel('End ID')
plt.title('Hammer vs Non-Hammer Win Percentage by End (Powerplay Ends)')
plt.ylim(0, 100)

# Annotate number of ends on top of bars
for i, end in enumerate(win_by_end.index):
    n_ends = ends_per_end[end]
    hammer_val = hammer_win_by_end[end]
    nonhammer_val = nonhammer_win_by_end[end]
    ax.text(i, max(hammer_val, nonhammer_val)+2, f'n={n_ends}', ha='center', fontsize=10)

plt.tight_layout()
plt.show()

```
```{python}
# 1️⃣ Add hammer_2plus flag and Powerplay_Status to full df
df['hammer_2plus'] = (df['score_hammer'] >= 2).astype(int)
df['Powerplay_Status'] = df['powerplay_value'].apply(lambda x: 'Powerplay' if x != 0 else 'No Powerplay')

# 2️⃣ Filter to ends 6 and 7
df_subset = df.copy()

# 3️⃣ Apply bins to df_subset
bins = [-float('inf'), -2, 0, 2, float('inf')]
labels = [
    'Behind (≤ -2)',
    'Tied or Down 1',
    'Up 1–2',
    'Up ≥ 3'
]

df_subset['score_diff_bin'] = pd.cut(
    df_subset['cumulative_score_diff'],
    bins=bins,
    labels=labels
)

# 4️⃣ Aggregate hammer 2+ %
win_stats = (
    df_subset.groupby(['score_diff_bin', 'Powerplay_Status'])
    .agg(
        hammer_2plus_pct=('hammer_2plus', lambda x: round(x.mean()*100,2)),
        n_ends=('hammer_2plus', 'count')
    )
    .reset_index()
)

win_stats_sorted = win_stats.sort_values(by='hammer_2plus_pct', ascending=False)
win_stats_sorted

```


















