---
title: "Behavior Regression: Power Play and Late-Phase Shot Selection"
format: html
execute:
  warning: false
  message: false
---

## Goal and definitions

- Unit: team-end (two rows per end). Treat rows as paired, not independent. 
- Phase restriction: late phase only, shot_id 16-22. 
- Behavior labels (shot selection only): 
    - Defensive = opponent-addressing (takeouts, peels, clears). 
    - Offensive = placement or pressure (draws, guards, raises). 
    - Neutral/unknown = through, no-shot, or unknown.

## Import Modules and Data

```{python}
import importlib.util
from pathlib import Path

import numpy as np
import pandas as pd
from plotnine import (
    ggplot,
    aes,
    geom_violin,
    geom_boxplot,
    geom_line,
    geom_point,
    geom_col,
    geom_smooth,
    geom_hline,
    geom_abline,
    labs,
    theme_minimal,
    scale_x_discrete,
)
import statsmodels.formula.api as smf
from scipy import stats
```

The stone-level cleaning script is run directly in this notebook to produce
a master table. I make take some precautions to ensure data quality.

```{python}
# load data.
CLEANING_PATH = Path("../code/stone_level_cleaning.py")
spec = importlib.util.spec_from_file_location("stone_level_cleaning",
                                              CLEANING_PATH)
cleaning = importlib.util.module_from_spec(spec)
spec.loader.exec_module(cleaning)

df = cleaning.stones_master.copy()

# Minimal cleanup
for col in ["has_hammer", "powerplay", "pre_end_score_diff", "task", "shot_id"]:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors="coerce")

# Use ints where safe; treat missing tasks as neutral (-1)
if "task" in df.columns:
    df["task"] = df["task"].fillna(-1).astype(int)
for col in ["has_hammer", "powerplay", "pre_end_score_diff", "shot_id"]:
    if col in df.columns:
        df[col] = df[col].fillna(0).astype(int)

# Quick sanity
preview_cols = [
    "match_id",
    "end_id",
    "team_id",
    "shot_id",
    "task",
    "powerplay",
    "has_hammer",
]
df[preview_cols].head()
```

## Task mapping (behavior labels)

This chunk defines the task-to-behavior mapping used in the study, then tags
every shot as offensive, defensive, or neutral. A mapping table is produced to
make the operational definition explicit and to show how many shots fall into
each category.

I assign each task to some behavior based on the curling rule-of-thumb
that offensive shots are those that seek to advance the scoring potential
by landing near the button and setting guards to protect scoring stones,
essentially ignoring the opponent's stones, and that defensive shots
are those that seek to mitigate opponent scoring potential via take-outs
of scoring stones and guards.

Conveniently, 0-5 are "slow stones" and 6-11 are "fast stones" (from Curlit)
which provide very good proxies for offensive/defensive behavior, respectively.

I include task labels from the data dictionary for reference.


```{python}
# Task labels for reference
task_labels = {
    0: "Draw",
    1: "Front",
    2: "Guard",
    3: "Raise/Tap-back",
    4: "Wick/Soft peel",
    5: "Freeze",
    6: "Take-out",
    7: "Hit and roll",
    8: "Clearing",
    9: "Double take-out",
    10: "Promotion take-out",
    11: "Through",
    -1: "No shot",
}

# Behavior groups (late-phase shot selection)
offensive_tasks = {0, 1, 2, 3, 5, 7}
defensive_tasks = {4, 6, 8, 9, 10}
neutral_tasks = {11, -1}

# Assign groups
conditions = [
    df["task"].isin(offensive_tasks),
    df["task"].isin(defensive_tasks),
    df["task"].isin(neutral_tasks),
]
choices = ["offensive", "defensive", "neutral"]
df["task_group"] = np.select(conditions, choices, default="neutral")

# mapping table
mapping_rows = []
for task_code, label in sorted(task_labels.items(), key=lambda x: x[0]):
    if task_code in offensive_tasks:
        group = "offensive"
    elif task_code in defensive_tasks:
        group = "defensive"
    elif task_code in neutral_tasks:
        group = "neutral"
    else:
        group = "neutral"
    count = int((df["task"] == task_code).sum())
    mapping_rows.append({
        "task": task_code,
        "task_label": label,
        "task_group": group,
        "count": count,
    })

mapping_df = pd.DataFrame(mapping_rows)
mapping_df
```

## Build team-end dataset and PP attribution

Here we aggregate the stone-level data to the team-end unit, attach end
context, and build the three-level PP exposure variable. We also create score
bins from pre-end score differential for descriptive stratification.

```{python}
keys = ["match_id", "end_id", "team_id"]

team_end = (
    df.groupby(keys, as_index=False)
    .agg(
        has_hammer=("has_hammer", "first"),
        pre_end_score_diff=("pre_end_score_diff", "first"),
        team_id1=("team_id1", "first"),
        team_id2=("team_id2", "first"),
    )
)

pp_end = (
    df.groupby(["match_id", "end_id"], as_index=False)["powerplay"]
    .max()
    .rename(columns={"powerplay": "pp_used_end"})
)
pp_team = (
    df.groupby(keys, as_index=False)["powerplay"]
    .max()
    .rename(columns={"powerplay": "pp_by_team"})
)

team_end = (
    team_end
    .merge(pp_end, on=["match_id", "end_id"], how="left")
    .merge(pp_team, on=keys, how="left")
)

team_end["pp_used_end"] = (team_end["pp_used_end"].fillna(0) != 0).astype(int)
team_end["pp_by_team"] = (team_end["pp_by_team"].fillna(0) != 0).astype(int)

team_end["pp_group"] = np.select(
    [
        team_end["pp_used_end"] == 0,
        (team_end["pp_used_end"] == 1) & (team_end["pp_by_team"] == 1),
        (team_end["pp_used_end"] == 1) & (team_end["pp_by_team"] == 0),
    ],
    ["nonPP", "PP_caller", "PP_noncaller"],
    default="nonPP",
)

team_end["pp_group"] = pd.Categorical(
    team_end["pp_group"],
    categories=["nonPP", "PP_caller", "PP_noncaller"],
    ordered=True,
)

# Score bins for descriptive plots
team_end["score_bin"] = pd.Categorical(
    np.where(
        team_end["pre_end_score_diff"] < 0,
        "trail",
        np.where(team_end["pre_end_score_diff"] > 0, "lead", "tied"),
    ),
    categories=["trail", "tied", "lead"],
    ordered=True,
)

team_end.head()
```

## Late-phase behavior metrics

This block filters to late shots (16-22), computes defensive/offensive/neutral
counts and shares per team-end, and constructs the behavior index (defensive
share minus offensive share). The same logic is applied to lateA (16-18) and
lateB (19-22) for timing diagnostics, then merged back into the team-end table.

```{python}
late_ids = [16, 17, 18, 19, 20, 21, 22]
lateA_ids = [16, 17, 18]
lateB_ids = [19, 20, 21, 22]


def summarize_phase(df_phase: pd.DataFrame, label: str) -> pd.DataFrame:
    counts = (
        df_phase.groupby(keys + ["task_group"]).size().unstack(fill_value=0)
    )
    for g in ["defensive", "offensive", "neutral"]:
        if g not in counts.columns:
            counts[g] = 0
    counts = counts[["defensive", "offensive", "neutral"]]
    counts = counts.rename(columns={
        "defensive": f"def_count_{label}",
        "offensive": f"off_count_{label}",
        "neutral": f"neu_count_{label}",
    })
    counts[f"shots_{label}"] = counts.sum(axis=1)

    denom = counts[f"shots_{label}"]
    counts[f"def_share_{label}"] = np.where(
        denom > 0, counts[f"def_count_{label}"] / denom, np.nan
    )
    counts[f"off_share_{label}"] = np.where(
        denom > 0, counts[f"off_count_{label}"] / denom, np.nan
    )
    counts[f"neu_share_{label}"] = np.where(
        denom > 0, counts[f"neu_count_{label}"] / denom, np.nan
    )
    counts[f"behavior_index_{label}"] = (
        counts[f"def_share_{label}"] - counts[f"off_share_{label}"]
    )

    return counts.reset_index()


late = df[df["shot_id"].isin(late_ids)].copy()
lateA = df[df["shot_id"].isin(lateA_ids)].copy()
lateB = df[df["shot_id"].isin(lateB_ids)].copy()

late_metrics = summarize_phase(late, "late")
lateA_metrics = summarize_phase(lateA, "lateA")
lateB_metrics = summarize_phase(lateB, "lateB")

team_end = (
    team_end
    .merge(late_metrics, on=keys, how="left")
    .merge(lateA_metrics, on=keys, how="left")
    .merge(lateB_metrics, on=keys, how="left")
)

# Main outcome alias
team_end["behavior_index"] = team_end["behavior_index_late"]

team_end.head()
```

## QA checks (ship / no-ship)

We first check coverage of late shots per team-end. Mixed doubles should yield
3 or 4 late shots per team-end; the coverage rates and counts by hammer confirm
whether late-phase metrics are broadly available.

```{python}
# 1) Coverage
coverage_4 = (team_end["shots_late"] >= 4).mean()
coverage_3 = (team_end["shots_late"] >= 3).mean()
coverage_by_hammer = (
    team_end.groupby("has_hammer")["shots_late"]
    .value_counts()
    .unstack(fill_value=0)
)

print("Coverage >=4 late shots:", round(coverage_4, 3))
print("Coverage >=3 late shots:", round(coverage_3, 3))
print("Late shots by has_hammer (counts):")
coverage_by_hammer
```

This check ensures the late-phase shares are internally consistent. The sum of
defensive, offensive, and neutral shares should be 1 for every team-end, with
only tiny floating-point error.

```{python}
# 2) Accounting: shares sum to 1
share_sum = (
    team_end["def_share_late"]
    + team_end["off_share_late"]
    + team_end["neu_share_late"]
)
max_abs_err = (share_sum - 1).abs().max()
print("Max abs error in share sums:", max_abs_err)
```

We next confirm that each PP group has a meaningful number of observations. If
PP_caller or PP_noncaller is too small, we would flag it before modeling.

```{python}
# 3) PP group sample sizes
team_end["pp_group"].value_counts()
```

This sanity table shows how many shots fall into each behavior group under the
chosen mapping. It verifies that defensive and offensive buckets are populated
and that neutral shots remain a small residual class.

```{python}
# 4) Sanity: show task mapping counts by group
(df.groupby("task_group")["task"].count()
 .rename("shot_count")
 .reset_index())
```

We document selection into power play by score state. This gives the
descriptive context for why PP might be associated with different late-phase
behavior.

```{python}
# 5) Selection: PP usage by score and hammer
pp_by_score = (
    team_end.groupby("score_bin")["pp_used_end"]
    .mean()
    .rename("pp_used_rate")
)
pp_by_score_hammer = (
    team_end.groupby(["score_bin", "has_hammer"])["pp_used_end"]
    .mean()
    .rename("pp_used_rate")
)

print("PP usage by score_bin:")
pp_by_score
```

Here we add hammer status to the selection summary to see whether PP usage
differs for teams with or without hammer within each score bin.

```{python}
print("PP usage by score_bin and has_hammer:")
pp_by_score_hammer
```

## Descriptive tables

We compute mean and median defensive share, offensive share, and behavior index
by PP group. These tables provide the first-pass descriptive comparisons before
any controls.

```{python}
metrics = ["def_share_late", "off_share_late", "behavior_index"]


def summary_table(group_cols):
    out = team_end.groupby(group_cols)[metrics].agg(["mean", "median"])
    out.columns = ["_".join(col) for col in out.columns]
    return out.reset_index()

# 1) By pp_group
summary_pp = summary_table(["pp_group"])
summary_pp
```

This table splits the same metrics by PP group and hammer status to show how
possession changes the descriptive pattern.

```{python}
# 2) By pp_group x has_hammer
summary_pp_hammer = summary_table(["pp_group", "has_hammer"])
summary_pp_hammer
```

This table stratifies by PP group and score bin so you can see how trailing,
tied, or leading teams differ in their late-phase behavior.

```{python}
# 3) By pp_group x score_bin
summary_pp_score = summary_table(["pp_group", "score_bin"])
summary_pp_score
```

## Plots

The following figures visualize the descriptive patterns. Each plot uses
plotnine to keep the graphics consistent across the notebook.

This violin+box plot summarizes the distribution of the behavior index by PP
group, showing both central tendency and spread.

```{python}
# 1) Behavior index by pp_group
plot_behavior_index = (
    ggplot(team_end, aes(x="pp_group", y="behavior_index"))
    + geom_violin(fill="#9ecae1", alpha=0.6, color="#2b6cb0")
    + geom_boxplot(width=0.2, outlier_alpha=0.25)
    + labs(
        title="Behavior index by PP group (late phase)",
        x="PP group",
        y="Behavior index (def - off)",
    )
    + theme_minimal()
)
plot_behavior_index
```

This line plot shows how mean defensive share varies by score state, with
separate lines for PP group. It highlights whether PP changes behavior
differently when trailing, tied, or leading.

```{python}
# 2) Mean defensive share by score_bin, lines by pp_group
mean_def = team_end.groupby(
    ["score_bin", "pp_group"], as_index=False
)["def_share_late"].mean()

plot_def_by_score = (
    ggplot(
        mean_def,
        aes(
            x="score_bin",
            y="def_share_late",
            color="pp_group",
            group="pp_group",
        ),
    )
    + geom_line()
    + geom_point()
    + scale_x_discrete(limits=["trail", "tied", "lead"])
    + labs(
        title="Mean late-phase defensive share by score bin",
        x="Score bin",
        y="Defensive share (late)",
        color="PP group",
    )
    + theme_minimal()
)
plot_def_by_score
```

This bar chart compares lateA versus lateB defensive share within each PP group
to provide a timing mechanism check.

```{python}
# 3) Timing split: lateA vs lateB defensive share by pp_group
mean_timing = (
    team_end.groupby(["pp_group"], as_index=False)
    .agg(
        def_share_lateA=("def_share_lateA", "mean"),
        def_share_lateB=("def_share_lateB", "mean"),
    )
)
mean_timing = mean_timing.melt(
    id_vars=["pp_group"],
    value_vars=["def_share_lateA", "def_share_lateB"],
    var_name="phase",
    value_name="def_share",
)
mean_timing["phase"] = mean_timing["phase"].str.replace(
    "def_share_", "", regex=False
)

plot_timing = (
    ggplot(mean_timing, aes(x="pp_group", y="def_share", fill="phase"))
    + geom_col(position="dodge")
    + labs(
        title="Late-phase defensive share: lateA vs lateB",
        x="PP group",
        y="Defensive share",
        fill="Phase",
    )
    + theme_minimal()
)
plot_timing
```

## Regression models

We fit the core specification with PP group, hammer, score differential, end
fixed effects, team fixed effects, and match fixed effects. Standard errors are
clustered at the match level, and we report the PP_caller and PP_noncaller
coefficients for the main late index and the two timing splits.

```{python}
model_df = team_end.copy()
model_df["has_hammer"] = model_df["has_hammer"].astype(int)

formula_base = (
    "{outcome} ~ C(pp_group, Treatment(reference='nonPP')) "
    "+ has_hammer + pre_end_score_diff + C(end_id) + C(team_id) + C(match_id)"
)


def fit_model(outcome: str):
    formula = formula_base.format(outcome=outcome)
    res = smf.ols(formula, data=model_df).fit(
        cov_type="cluster", cov_kwds={"groups": model_df["match_id"]}
    )
    return res


models = {
    "behavior_index": fit_model("behavior_index"),
    "behavior_index_lateA": fit_model("behavior_index_lateA"),
    "behavior_index_lateB": fit_model("behavior_index_lateB"),
}

pp_terms = {
    "PP_caller": "C(pp_group, Treatment(reference='nonPP'))[T.PP_caller]",
    "PP_noncaller": "C(pp_group, Treatment(reference='nonPP'))[T.PP_noncaller]",
}

rows = []
for model_name, res in models.items():
    for label, term in pp_terms.items():
        rows.append({
            "model": model_name,
            "term": label,
            "coef": res.params.get(term, np.nan),
            "se": res.bse.get(term, np.nan),
            "pvalue": res.pvalues.get(term, np.nan),
            "nobs": int(res.nobs),
            "r2": res.rsquared,
        })

reg_table = pd.DataFrame(rows)
reg_table
```

## Model diagnostics

We evaluate residual structure and influence for the main late-phase model. The
diagnostics below summarize residual location and scale, outliers, and
influence, and the plots check for curvature or heavy tails.

```{python}
main_res = models["behavior_index"]
influence = main_res.get_influence()

diag_df = pd.DataFrame({
    "fitted": main_res.fittedvalues,
    "resid": main_res.resid,
    "stud_resid": influence.resid_studentized_internal,
    "leverage": influence.hat_matrix_diag,
    "cooks_d": influence.cooks_distance[0],
})

n_obs = len(diag_df)
diag_summary = pd.DataFrame({
    "n_obs": [n_obs],
    "resid_mean": [diag_df["resid"].mean()],
    "resid_sd": [diag_df["resid"].std(ddof=1)],
    "stud_abs_gt2": [(diag_df["stud_resid"].abs() > 2).sum()],
    "stud_abs_gt3": [(diag_df["stud_resid"].abs() > 3).sum()],
    "cooks_gt_4n": [(diag_df["cooks_d"] > (4 / n_obs)).sum()],
    "cooks_max": [diag_df["cooks_d"].max()],
    "leverage_max": [diag_df["leverage"].max()],
})
diag_summary
```

```{python}
plot_resid = (
    ggplot(diag_df, aes(x="fitted", y="resid"))
    + geom_point(alpha=0.4)
    + geom_hline(yintercept=0, color="#666666")
    + labs(
        title="Residuals vs fitted values",
        x="Fitted values",
        y="Residuals",
    )
    + theme_minimal()
)
plot_resid
```

```{python}
qq_df = diag_df[["resid"]].dropna().sort_values("resid").reset_index(drop=True)
qq_df["theoretical"] = stats.norm.ppf((qq_df.index + 0.5) / len(qq_df))
qq_df["sample"] = qq_df["resid"]

plot_qq = (
    ggplot(qq_df, aes(x="theoretical", y="sample"))
    + geom_point(alpha=0.4)
    + geom_abline(slope=1, intercept=0, color="#2b6cb0")
    + labs(
        title="Q-Q plot of residuals",
        x="Theoretical normal quantiles",
        y="Sample residual quantiles",
    )
    + theme_minimal()
)
plot_qq
```

The residuals are centered near zero with moderate spread, and the
residual-versus-fitted plot shows no strong curvature. The discrete outcome
produces visible banding, which is expected given the 1/3 and 1/4 increments.
Studentized residuals above 2 are present but rare (197 of 5,274), and only 9
exceed 3. Cook's distances are small (max 0.0025) and the highest leverage is
about 0.10, indicating no single team-end drives the fit. The Q-Q plot shows
slight tail deviations, but clustering by match and the large sample mitigate
concerns about non-normal errors.

## Optional positional validation (one metric)

To validate the behavioral interpretation without redefining it, we compute a
single positional measure: opponent stones that go off-sheet during late shots.
We infer which stones belong to the opponent based on the fixed stone index
ownership (1-6 for team_id1, 7-12 for team_id2), detect transitions to the off-
sheet sentinel, and aggregate them by team-end.

```{python}
# Count opponent stones that go off-sheet during late shots.
# Stone indices 1-6 belong to team_id1; stones 7-12 belong to team_id2.

stone_ids = list(range(1, 13))

df_sorted = df.sort_values(["match_id", "end_id", "shot_id"]).copy()

cols_1_6 = []
cols_7_12 = []

for i in stone_ids:
    x_col = f"stone_{i}_x"
    y_col = f"stone_{i}_y"
    off_col = f"stone_{i}_off"
    prev_col = f"stone_{i}_off_prev"
    to_col = f"stone_{i}_to_off"

    df_sorted[off_col] = (df_sorted[x_col] == 4095) | (df_sorted[y_col] == 4095)
    df_sorted[prev_col] = (
        df_sorted.groupby(["match_id", "end_id"])[off_col]
        .shift(1)
        .fillna(False)
    )
    df_sorted[to_col] = (~df_sorted[prev_col]) & (df_sorted[off_col])

    if i <= 6:
        cols_1_6.append(to_col)
    else:
        cols_7_12.append(to_col)

# Per shot, count new offsheet stones for each side
for col_list, out_col in [(cols_1_6, "to_off_1_6"), (cols_7_12, "to_off_7_12")]:
    df_sorted[out_col] = df_sorted[col_list].sum(axis=1).astype(int)

# Opponent removals per shot
team1_mask = df_sorted["team_id"] == df_sorted["team_id1"]
df_sorted["opp_offsheet_on_shot"] = np.where(
    team1_mask, df_sorted["to_off_7_12"], df_sorted["to_off_1_6"]
)

late_shots = df_sorted[df_sorted["shot_id"].isin(late_ids)].copy()
opp_off = (
    late_shots.groupby(keys, as_index=False)["opp_offsheet_on_shot"].sum()
    .rename(columns={"opp_offsheet_on_shot": "opp_offsheet_late"})
)

team_end = team_end.merge(opp_off, on=keys, how="left")
team_end["opp_offsheet_late"] = team_end["opp_offsheet_late"].fillna(0)

corr = (
    team_end[["def_share_late", "opp_offsheet_late"]]
    .corr(method="spearman")
    .iloc[0, 1]
)
print("Spearman corr(def_share_late, opp_offsheet_late):", round(corr, 3))
```

The validation plot visualizes the relationship between defensive share and
opponent removals, with a fitted linear trend to clarify direction.

```{python}
plot_validation = (
    ggplot(team_end, aes(x="def_share_late", y="opp_offsheet_late"))
    + geom_point(alpha=0.4)
    + geom_smooth(method="lm", se=False, color="#2b6cb0")
    + labs(
        title="Validation: defensive share vs opponent stones off-sheet",
        x="Defensive share (late)",
        y="Opponent stones removed (late)",
    )
    + theme_minimal()
)
plot_validation
```

## One-sentence thesis

We operationalize behavior as late-phase shot selection (defensive vs offensive
task types), separate PP caller vs opponent, and estimate PP-associated
behavioral shifts conditional on hammer, score, and end with team and match
controls plus clustered inference; timing splits show when the shift occurs.

## Regression analysis write-up

This analysis uses team-end as the unit and models behavior as a late-phase
shot-selection index: `behavior_index = def_share_late - off_share_late`. The
core specification is fixed-effects OLS with `nonPP` as the reference group:

`behavior_index ~ C(pp_group) + has_hammer + pre_end_score_diff + C(end_id)
+ C(team_id) + C(match_id)`, with standard errors clustered at `match_id`.
Identical specifications are fit for the timing splits `behavior_index_lateA`
and `behavior_index_lateB`. The sample includes 5,274 team-end rows (2,637
ends), and late-shot coverage is complete: all rows have at least three late
shots and half have four, consistent with mixed doubles rules.

Model selection is driven by interpretability and structure. The outcome is a
difference in shares, which behaves approximately continuously despite its
1/3 and 1/4 discreteness, so OLS provides a direct interpretation in share
points. Team and match fixed effects absorb persistent strategic differences
that are plausibly correlated with PP usage, avoiding the stronger independence
assumption required by random-effects models. End fixed effects control for
systematic end-level shifts. Clustering by match addresses within-match
correlation and the paired structure of team-ends.

In the main model, PP is associated with a shift toward more defensive shot
selection for both teams relative to non-PP ends. The PP caller coefficient is
0.068 (SE 0.030, p=0.024), while the PP non-caller coefficient is 0.449
(SE 0.035, p≈1.3e-37). This implies that the opponent response is much larger
than the caller's shift after controlling for hammer, score differential, end,
team, and match fixed effects. The model R² is 0.232.

Timing splits clarify when this shift occurs. In lateA (shots 16-18), the PP
caller effect is 0.128 (SE 0.038, p=8.5e-4) and the PP non-caller effect is
0.516 (SE 0.046, p≈1.3e-29). In lateB (shots 19-22), the PP caller effect is
0.009 (SE 0.038, p=0.82; not significant), while the PP non-caller effect
remains large at 0.414 (SE 0.043, p≈3.1e-22). This pattern indicates that the
caller’s defensive shift happens early, whereas the non-caller remains
defensive throughout the late phase.

Diagnostics support the linear specification. Residuals are centered near zero
with moderate spread (SD ≈ 0.55), and the residual-versus-fitted plot shows no
strong curvature. Discreteness appears as banding, which is expected from the
shot-count denominators. Studentized residuals above 2 are uncommon (197 of
5,274) and only 9 exceed 3. Cook's distances are small (max 0.0025) and the
largest leverage is about 0.10, indicating no single team-end dominates the
fit. The Q-Q plot shows mild tail deviations, which is typical in large samples
and is mitigated by clustered inference.

Selection patterns are consistent with strategic use of PP: the end-level PP
rate is about 0.265 when trailing or leading but only 0.113 when tied. The
controlled model includes score differential and fixed effects to reduce bias
from this selection, but the results should still be interpreted as
associations rather than causal effects.

The positional validation supports the behavior label: the Spearman
correlation between `def_share_late` and opponent stones removed late is 0.804,
indicating that defensive shot selection corresponds to opponent stone
removals. The main limitation is that “behavior” is defined by shot-task
categories rather than positional intent; still, it is the most direct signal
available in this dataset under the project constraints.
