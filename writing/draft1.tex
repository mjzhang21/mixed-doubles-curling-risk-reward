\documentclass{article}
\usepackage{amsmath}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{xcolor}
\usepackage{caption}

\title{Analysis of Power Play Behavior and Counter Play in Mixed Doubles Curling\\
  \large CSAS 2026 Data Challenge Submission}

\date{[15 January 2026]}



\begin{document}

\begin{titlepage}
  \maketitle

\end{titlepage}

% Note: % is comment character, \ backslash is the escape character (needed for $, %, etc.)

% New paragraphs will be formed automatically similar to quarto, just leave a blank line in between
% lines. Inline math can be called by wrapping with $, for example $ math equation$.


\section{Introduction}

% briefly outline what the purpose of the data challenge is exactly
% -> there isn o data anlysis done on mixed doubles curling
% all mixed doubles curling strategy and intuition relies on
% strategy formulated from the tradtional game.
% this is why we have the data challenge, is so that we can develop
% strategy independent of the 4 person game.

Mixed Doubles Curling is the product of the Internation Olympic Committee's
request for a variatiant of the game that is more fast-paced, dynamic,
high-risk, and less likely to fall into specific patterns determined by a
game strategy.

The unique rules of the Mixed Doubles game including the Modified Free Guard
Zone (MFGZ), two pre-placed stones, the hammer being transferred even on a blank,
only eight ends, and of course the power play, necessitate new tactical and
strategic decisionmaking on the ice. These modifications are intended to keep more
stones in play, increasing the odds of big ends and raising the stakes for a
single end. 

Mixed Doubles' novelty, however, means that little-to-no data-driven strategy exists
yet for the sport. Analysts note (source pending) that currently, mixed doubles teams
have to "play the sheet", i.e., a tactical game.

Of particular note is the power play, a concept entirely new to curling. The power play
can be used by each team once per team if they have the hammer. In power play, the
pre-placed stones, which usually are a front guard and a button scoring stone
for the non-hammer and hammer team respectively, are moved off to the side. This opens
up the sheet and requires a fundamentally different approach.

Right now, coaches and analysts only have intuition (source pending) from the traditional
game as how to effectively play the power play. But if there is anything to learn
from traditional curling, a strategic approach is always more effective than playing pure
tactics; and thus at the professional level it is the teams' best interest that proper
strategy on when to use the power play, how to use it, and how to respond to it, is
developed.

% the key focus of the data challenge is the power play, for which
% we have no reliable strategy because this is a novel rule
% powerplay questions: how and when and why is it used
% how should you use it or or respond to it etc

Using data from two World Championships and one Winter Olympics,
this paper offers the first analysis of strategic behavior surrounding the Power play
in professional Mixed Doubles Curling. We first show that teams tend to adopt more
defensive behaviors when using the power play, particularly in the later ends, but that
these strategic tendencies are not consistent across teams or championships. We then
focus on non-hammer team behavior, by analyzing common counter power play shot types and
find that while different opens do not significantly affect expeced scoring outcomes for
the non-hammer team, they do produce significant differences in execution quality
and cumulative score dynamics. Despite teams systemically varying their shot
choice based on game context, the data provides no evidence that any particular 
counter-strategy is objectively preferable when opening an end agaisnt the Power Play.

% THESES:
% what behavior is seen during powerplay -> these behaviors are seen -> do they lead to anything

% Defensive behavior is observed during powerplay typically in later ends, strategic trends
% are not apparent across teams or championships. 

% The different types of shots to counter the powerplay do not have significant differences
% in expected HT or NHT score but they have significant differences in execution score
% & cumulative score differences. 
% -> Teams tend to use different shots in different cumulative score differences, but
% the data suggests there is no reason to prefer different behavior when opening an end as NHT
% during Power play.


\subsection{Literature Review}

% bring up scarcity of resources and limitations of extant literature

\section{Data}

% source is curlit

% Data collection was that curlit analysts entered the stone positions onto a softeware and evaluated
% shot quality on objective criteria (awarding points)

% 2 world champsionships 1 winter olympics (beijing 2022)

% This is the first data set that:
% 1. Contains stone-level coordiante data for geometric analyses
% 2. Contains powerplay-end level data for mixed doubles curling
% 3. Objective qualifiers for shot-type and shot-execution

% basic histograms which describe the data,
% e.g. endid, powerplay 0,1,2, count normal/powerplay ends
% how many shots every noc hits
% how often each shot is shots


\section{Methodology}
\subsection{Power Play Behavior Clustering}
% Alejandro
% std. coordinates
% estimate behavior class binary on end-level predictor set

% finding of mine was that behavior 


% Bridge section flowwwww

% The behavior of the HT is much easier to identify during power play
% 

% Once power play behavior has been identified, clustering analysis
% for first-stone level data is used to identify ideal response
% types by the NHT


\subsection{First-shot NHT Clustering}

% Mark
% std. coordinates
% use HDBScan for clustering -> visualize w/ PCA, tSNE
% cluster quality evaluated on coverage, score, and cluster stability
% use welch ANOVA and KW-test, use post-hoc test to determine differences between clusters
% hypothesis test: test if there is at least one group that is significantly
% different from another

% assumptions: ind, approx. normal (for anova), skewed (for kw-test)
The following is a brief summary of the preprocessing steps applied prior
to analysis. After the coordinates were standardized, the stone level data were 
merged with the end level data and filtered to the first shot of the end. The
columns for stones 3 to 6 and 9 to 12 were dropped as they are able
to be played in the first shot. Columns for stone 2 and 8 were combined 
and shifted into one column for stone 2 due to both belonging to the 
non-hammer team. As for stones 1 and 7, both columns represented preplaced
stones, although the designation of guard or house stone was unclear for each
row. Thus, the coordinates were swapped when either stone 1 had coordinates for 
the hammer preplaced house stone or stone 7 had coordinates for the 
non-hammer guard.

To explore potential clusters, PCA, t-SNE and UMAP were applied onto the 
6-dimensional coordinate data consisting of the x and y coordinates for 
stone 1, 2 and 7. HDBSCAN was selected due to non-circular clusters appearing
in the 2-D visualizations from graphing 2 components of PCA, t-SNE and UMAP.
Parameters of minimum cluster size = 9 and min samples = 1 were chosen from
a grid search to balance and maximize Density-Based-Clustering-Validation score
and coverage. Cluster quality was determined from DBCV score, coverage, excluded 
noise sillouhete score and cluster membership probabilities. Finally, the clusters
were visualized by color on 2-D components of the dimensionality reduction 
techniques to confirm cluster separation.

To compare performance metrics across the clusters, continuous variables 
approximately normally distributed were analyzed using Welch's one-way ANOVA.
Heavily skewed ordinal variables were assessed with the Kruskal-Wallis H test.
Post-hoc pairwise comparisons were performed using the Games–Howell test for ANOVA 
results and the Dunn test for Kruskal-Wallis outcomes. Cluster groups were defined 
as C0 (n=35), C1 (n=75), and C3 (n=67). Values are presented as mean with confidence
intervals or medians with 25th and 75th percentile,as appropriate, and detailed
results for all variables are provided in Table~\ref{tab:cluster_test}.


\begin{table}[t]
\centering
\includegraphics[width=0.8\textwidth]{img/cluster_test.pdf}
\caption{Values are presented as mean (95\% CI) or median (Q1, Q3). 
C0: Cluster 0, C1: Cluster 1, C3: Cluster 3.
P values indicate the statistical inference result of overall comparisons.}
\label{tab:cluster_test}
\end{table}



\section{Results}
Cumulative score difference differed significantly across clusters (Welch’s 
ANOVA, $p=0.015$; Table~\ref{tab:cluster_test}), with the highest mean observed in
C1 (6.00, 95\% CI 5.07--6.93) and the lowest in C0 (3.51, 95\% CI 2.06--4.97).
Post-hoc analysis indicated a significant difference between C0 and C1 ($p=0.014$),
while differences between C0 and C3 ($p=0.317$) and C1 and C3 ($p=0.245$) were 
not statistically significant. Points also varied across clusters (Kruskal-Wallis
H test, $p=0.003$; Table~\ref{tab:cluster_test}), with a significant post-hoc 
difference between C1 and C3 ($p=0.002$) but not between C0 and C1 ($p=0.129$)
or C0 and C3 ($p=1.000$). Hammer and non-hammer scores did not differ significantly
across clusters ($p=0.958$ and $p=0.904$, respectively; Table~\ref{tab:cluster_test}).
Overall, these results indicate that cumulative score difference and points
showed cluster-specific variation, while hammer-related outcomes were similar
across groups.



\section{Discussion}

% 1st - summarize
% 2nd - why is your approach the best
% 3rd - limitations. what question might someone else want to answer that we can't address


% bring up the most interesting and insightful results
% bring up the implications, make actionable recommendations

% alejandro: curling strategy says to enter with a game-plan
% game-plans for how to use powerplay are not observed with this
% data. 

\subsection{Limitations}
% lack of powerplay sample size
% very skewed data. task, points, expected hammer points
% data quality. i.e. inconsistent coordinate assignments, incosistent column assignments

% freeze vs draw inconsistency 

% imbalanced data with logical end devisions before vs after MFGZ 

% one of the clusters does not identify raise / tap-backs on the hammer stone

% the draw cluster has a very small sample size but is recognized as a cluster


\subsection{Conclusion}
% quick summary

%\section{Appendices}
%if there is a need for code appendix or otherwise, we'll put it at the botton. 
\bibliographystyle{plainnat}
\bibliography{../references}
%i have my latex in vscode compiled to use natbib, not bibtex. it will work for you
% but i havent got mine working yet, once i set it back we will use APA

\end{document}

