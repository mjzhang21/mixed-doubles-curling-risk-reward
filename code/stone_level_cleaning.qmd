---
title: "CSAS 2026: Reconstructing an End"
author: "Alejandro Haerter"
date: "2026-01-01"
format:
  pdf:
    colorlinks: true
    linkcolor: blue
    number-sections: true
    geometry: margin=1in
    fontsize: 11pt 
---

# Data Assembly and Cleaning

Import modules and data.

```{python}
import pandas as pd
import numpy as np

competition_df = pd.read_csv('../data/Competition.csv')

competitors_df = pd.read_csv('../data/Competitors.csv')

ends_df = pd.read_csv('../data/Ends.csv')

games_df = pd.read_csv('../data/Games.csv')

stones_df = pd.read_csv('../data/Stones.csv')

teams_df = pd.read_csv('../data/Teams.csv')
```

Make `MatchID` out of a combination of `CompetitionID`, `SessionID`, and `GameID`.
This is the unique key going forward.

```{python}
games_df["MatchID"] = (
    games_df["CompetitionID"].astype(str) + "_" +
    games_df["SessionID"].astype(str) + "_" +
    games_df["GameID"].astype(str)
)

ends_df["MatchID"] = (
    ends_df["CompetitionID"].astype(str) + "_" +
    ends_df["SessionID"].astype(str) + "_" +
    ends_df["GameID"].astype(str)
)
```

Create `game_ends` via merger of `ends_df` and `games_df`.
This will attach game level information to each end.

```{python}
game_ends = (
    ends_df
    .merge(
        games_df,
        on="MatchID",
        how="left",
        validate="many_to_one"
    )
)
```

That merger duplicates the redundant ID columns, affixing them with `_y`, and affixes the existing ones with
`_x`.

```{python}
# remove duplicate key columns from the right side
game_ends = game_ends.drop(columns=["CompetitionID_y", "SessionID_y", "GameID_y"])
game_ends.rename(
    columns={
        "CompetitionID_x": "CompetitionID",
        "SessionID_x": "SessionID",
        "GameID_x": "GameID"
    },
    inplace=True
)
```

While a `PowerPlay` column exists, for any end which Power Play was not used,
there is no information on which team has the hammer. We need to create a
column `HasHammer` which gives us this useful information.

There are two ways to identify whether a team has the hammer in a given end.
- **Iteratively:** Start with the first End in a game. The team with the Last
stone first end (LSFE) has the hammer the first end. Depending on which
team scores, the hammer will be kept or transferred. This way, the hammer can be
followed through the length of the game.
- **Contextually:** The team which throws the first stone, ie. the `TeamID` for
which `ShotID == 7` must *not* have the hammer.

Both of these approaches should correctly track the Hammer in theory. I opt to
implement both as a data validation measure. If there are discrepancies, the
particular End has bad data.

### Iterative approach: HasHammer_I

Per the CSAS2026 data dictionary:
"`LSFE` – Last Stone First End. This column indicates which team threw the last
stone in the first end of the match. In curling parlance, this is called
starting with “the hammer”. A 0 value means that NOC2 threw the last stone in
the first end, a 1 means that NOC1 threw last.""

```{python}
# helper: map LSFE (0 means NOC2, 1 means NOC1) to TeamID that starts with hammer in End 1
def initial_hammer_teamid(row):
    return row["TeamID1"] if row["LSFE"] == 1 else row["TeamID2"]
cols = [
    "MatchID","EndID","TeamID","Result",
    "TeamID1","TeamID2","LSFE"
]
ge = game_ends[cols].copy()
ge.sort_values(["MatchID", "EndID"], inplace=True)
def assign_hammer_i(df):
    team1 = df["TeamID1"].iloc[0]
    team2 = df["TeamID2"].iloc[0]
    hammer = initial_hammer_teamid(df.iloc[0])
    out = []
    for _, end_rows in df.groupby("EndID", sort=True):
        end_rows = end_rows.copy()
        end_rows["HammerTeamID_I"] = hammer
        out.append(end_rows)
        totals = end_rows.groupby("TeamID")["Result"].sum().to_dict()
        scored = (totals.get(team1, 0) or 0) + (totals.get(team2, 0) or 0)
        if scored > 0:
            scoring_team = team1 if totals.get(team1, 0) > totals.get(team2, 0) else team2
            hammer = team2 if scoring_team == team1 else team1
    return pd.concat(out, ignore_index=True)
ge_hammer_i = ge.groupby("MatchID", group_keys=False).apply(assign_hammer_i)
ge_hammer_i["HasHammer_I"] = (ge_hammer_i["TeamID"] == ge_hammer_i["HammerTeamID_I"])
game_ends = (
    game_ends
    .merge(
        ge_hammer_i[["MatchID", "EndID", "TeamID", "HammerTeamID_I", "HasHammer_I"]],
        on=["MatchID", "EndID", "TeamID"],
        how="left",
        validate="one_to_one"
    )
)
```

### Contextual approach: HasHammer_C
The team that throws the first stone (ShotID == 7) does *not* have the hammer.
```{python}
if "MatchID" not in stones_df.columns:
    stones_df["MatchID"] = (
        stones_df["CompetitionID"].astype(str) + "_" +
        stones_df["SessionID"].astype(str) + "_" +
        stones_df["GameID"].astype(str)
    )
first_throw = (
    stones_df.loc[stones_df["ShotID"] == 7, ["MatchID", "EndID", "TeamID"]]
    .drop_duplicates()
    .rename(columns={"TeamID": "FirstStoneTeamID"})
)
hammer_c = (
    game_ends[["MatchID", "EndID", "TeamID"]]
    .merge(first_throw, on=["MatchID", "EndID"], how="left", validate="many_to_one")
)
hammer_c["HammerTeamID_C"] = np.where(
    hammer_c["TeamID"] != hammer_c["FirstStoneTeamID"],
    hammer_c["TeamID"],
    pd.NA
)
hammer_c["HammerTeamID_C"] = (
    hammer_c.groupby(["MatchID", "EndID"])["HammerTeamID_C"]
    .transform("max")
)
hammer_c["HasHammer_C"] = (hammer_c["TeamID"] == hammer_c["HammerTeamID_C"])
game_ends = (
    game_ends
    .merge(
        hammer_c[["MatchID", "EndID", "TeamID", "HammerTeamID_C", "HasHammer_C"]],
        on=["MatchID", "EndID", "TeamID"],
        how="left",
        validate="one_to_one"
    )
)
```

Quick checks for missing hammer info and disagreements between methods.

```{python}
hammer_check = game_ends[["MatchID", "EndID", "TeamID", "HasHammer_I", "HasHammer_C"]].copy()

missing_i = hammer_check["HasHammer_I"].isna().sum()
missing_c = hammer_check["HasHammer_C"].isna().sum()

mismatch = hammer_check.dropna(subset=["HasHammer_I", "HasHammer_C"])
mismatch = mismatch[mismatch["HasHammer_I"] != mismatch["HasHammer_C"]]
mismatch_ends = mismatch.drop_duplicates(["MatchID", "EndID"]).shape[0]

print("Missing HasHammer_I rows:", missing_i)
print("Missing HasHammer_C rows:", missing_c)
print("End-level mismatches (I vs C):", mismatch_ends)

mismatch.head()
```

There are five cases where they do not match. Once stone-level information is fully merged,
I will defer to each case invidually.

### Stone-Level Data

Build a master stone-level table (one row per stone toss) by merging stone, end, and game context.

```{python}
if "MatchID" not in stones_df.columns:
    stones_df["MatchID"] = (
        stones_df["CompetitionID"].astype(str) + "_" +
        stones_df["SessionID"].astype(str) + "_" +
        stones_df["GameID"].astype(str)
    )

stones_master = (
    stones_df
    .merge(
        game_ends,
        on=["MatchID", "EndID", "TeamID"],
        how="left",
        validate="many_to_one",
        suffixes=("", "_end")
    )
)

stones_master = stones_master.drop(['CompetitionID', 'GameID', 'SessionID',
                                    'CompetitionID_end', 'GameID_end', 'SessionID_end']
                                    , axis=1)
stones_master.head()
```

Check that the team throwing first (ShotID == 7) does not have the hammer.

```{python}
first_shot = stones_master.loc[stones_master["ShotID"] == 7]
first_shot["HasHammer_I"] = first_shot["HasHammer_I"].fillna(False)
first_shot["HasHammer_C"] = first_shot["HasHammer_C"].fillna(False)

print("ShotID==7 with HasHammer_I:", first_shot["HasHammer_I"].sum())
print("ShotID==7 with HasHammer_C:", first_shot["HasHammer_C"].sum())
first_shot[(first_shot["HasHammer_I"]) | (first_shot["HasHammer_C"])].head()
```

When `ShotID == 7`, the team which threw the stone cannot have the hammer. `HasHammer_C`
has no such instances but `HasHammer_I` has five, which are the same from the earlier mismatch.
I defer to `HasHammer_C` for a more reliable tracker, then.

These exceptions are unlikely a data quality issue and probably stem from an issue
with the iterative method code, but this does not warrant a fix as the contextual
method seems completely fine.

The `stones_master` dataframe is finalized below.

```{python}
stones_master = stones_master.drop(['HasHammer_I', 'HammerTeamID_I'], axis=1)
stones_master['HammerTeamID_C'] = stones_master['HammerTeamID_C'].astype(int)
stones_master['TimeOut'] = stones_master['TimeOut'].fillna(0)
stones_master['PowerPlay'] = stones_master['PowerPlay'].fillna(0)
```