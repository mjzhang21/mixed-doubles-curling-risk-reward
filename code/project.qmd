


```{python}
import pandas as pd
import numpy as np

df_competition = pd.read_csv("../data/Competition.csv")
df_competitors  = pd.read_csv("../data/Competitors.csv")
df_games        = pd.read_csv("../data/Games.csv")
df_teams        = pd.read_csv("../data/Teams.csv")
df_ends         = pd.read_csv("../data/Ends.csv")
df_stones       = pd.read_csv("../data/Stones.csv")

```
Merge the ends and games data with the stones data.
```{python}

merged = pd.merge(
    df_stones,
    df_ends,
    on=["CompetitionID","SessionID","GameID","EndID","TeamID"],
    how="left"
)

df = pd.merge(
    merged,
    df_games,
    on=["CompetitionID","SessionID","GameID"],
    how="left"
)
df = pd.merge(
    df,
    df_teams,
    on=["CompetitionID","TeamID"],
    how="left"
)
df = pd.merge(
    df,
    df_competition,
    on=["CompetitionID"],
    how="left"
)
df.columns = df.columns.str.lower().str.replace('id', '_id')
df['match_id'] = df['competition_id'].astype(str) + '_' + df['session_id'].astype(str) + '_' + df['game_id'].astype(str)
float_cols = df.select_dtypes(include=['float64']).columns
df[float_cols] = df[float_cols].astype(np.float32)
df.head()
```
```{python}
df.info()
```
```{python}
df.isnull().sum()
```
```{python}
categorical_cols = [
    'competition_id',
    'end_id',
    'player_id',
    'task',
    'handle',
    'sheet',
    'lsfe',
    'winner',
    'powerplay',
    'timeout',
    'points'
]


for col in categorical_cols:
    freq_table = df[col].value_counts(dropna=False).reset_index()
    freq_table.columns = [col, 'Frequency']
    freq_table['Percentage'] = (freq_table['Frequency'] / freq_table['Frequency'].sum() * 100).round(2)
    
    print(f"Frequency table for {col}:\n", freq_table, "\n")
```

Fill in data that is supposed to be 0.
```{python}
cols_to_fill = ['powerplay', 'timeout']
df[cols_to_fill] = df[cols_to_fill].fillna(0)
df[cols_to_fill] = df[cols_to_fill].astype('int')

```
Turn -1 into NA or invalid data.
```{python}
columns_to_fix = ['task', 'handle', 'points']

df[columns_to_fix] = df[columns_to_fix].replace(-1, pd.NA)

```
Drop rows which dont have any coordinate data.
```{python}
df = df.dropna(subset=["stone_3_x"])
df.isnull().sum()
```
```{python}
count = 0
df=df.sort_values(by="shot_id")
for (mid, eid), game in df.groupby(['match_id', 'end_id']):
    print(f"Match {mid}, End {eid}")
    print(game[["team_id","lsfe","resultstr1","resultstr2","shot_id"]])
    print("-" * 50)
    count += 1
    if count >= 10:
        break
```
Create hammer column that alternates according to curling rules.
```{python}
import pandas as pd

df = df.sort_values(["match_id"])

df["hammer"] = -1 

for mid, game in df.groupby(["match_id"]):
    game = game.sort_values("end_id")
    
    team1 = game["team_id1"].iloc[0]
    team2 = game["team_id2"].iloc[0]

    lsfe = game["lsfe"].iloc[0] 
    hammer_val = lsfe  
    
    # Loop through ends
    for eid, end in game.groupby("end_id"):
        # Assign hammer for this end
        df.loc[end.index, "hammer"] = end["team_id"].apply(
        lambda tid: hammer_val if tid == team1 else (1 - hammer_val)
    )
        
        # Compute points for each team in this end
        points_team1 = end.loc[end["team_id"] == team1, "result"].iloc[0]
        points_team2 = end.loc[end["team_id"] == team2, "result"].iloc[0]
        
        # If hammer team scored, switch hammer for next end
        if (hammer_val == 1 and points_team1 > 0) or (hammer_val == 0 and points_team2 > 0):
            hammer_val = 1 - hammer_val 

```
```{python}
count = 0
df = df.sort_values(by="shot_id")
for (mid, eid), game in df.groupby(['match_id', 'end_id']):
    print(f"Match {mid}, End {eid}")
    print(game[["team_id","lsfe","result","hammer"]])
    print("-" * 50)
    count += 1
    if count >= 10:
        break
```
Fix invalid/ mistyped result and team id.
```{python}
shots_per_team = df.groupby(["match_id","end_id","team_id"]).size()
print(shots_per_team.describe())
print(shots_per_team[shots_per_team > 5])
cid, sid, gid, eid= 24250026, 18, 1, 9
df_invalid_shots = df[(df["competition_id"] == cid) &
            (df["session_id"] == sid) &
            (df["game_id"] == gid) &
            (df["end_id"] == eid)][["team_id","end_id","result"]]

print(df_invalid_shots)
df.loc[25375, ["team_id", "result"]] = [37, 1]
```
```{python}
import matplotlib.pyplot as plt

mean_points = df.groupby("end_id")["result"].mean()
plt.bar(mean_points.index.astype(str), mean_points.values, color='skyblue')
plt.title("Average points per end")
plt.xlabel("End")
plt.ylabel("Average Points")
plt.show()
```
```{python}
df[df["result"] >5][["match_id","end_id","result"]]
```
```{python}
df.loc[df["result"] > 5, "result"] = pd.NA
```
```{python}
mean_points = df.groupby("end_id")["result"].mean()
plt.bar(mean_points.index.astype(str), mean_points.values, color='skyblue')
plt.title("Average points per end")
plt.xlabel("End")
plt.ylabel("Average Points")
plt.show()
```
Average points per end looks more evenly spread now.

```{python}
df = df.dropna(subset=["result"])
null_counts = df.isnull().sum()
print(null_counts)
```
Check if all stone coordinates are valid
```{python}
x_cols = ['stone_1_x',
            'stone_2_x',
            'stone_3_x',
            'stone_4_x',
            'stone_5_x',
            'stone_6_x',
            'stone_7_x',
            'stone_8_x',
            'stone_9_x',
            'stone_10_x',
            'stone_11_x',
            'stone_12_x']
y_cols   = ['stone_1_y',
            'stone_2_y',
            'stone_3_y',
            'stone_4_y',
            'stone_5_y',
            'stone_6_y',
            'stone_7_y',
            'stone_8_y',
            'stone_9_y',
            'stone_10_y',
            'stone_11_y',
            'stone_12_y']  
             
x_min, x_max = 0, 1500
y_min, y_max = 0, 3000

# Create masks column by column
x_ok = (df[x_cols] >= x_min) & (df[x_cols] <= x_max) | (df[x_cols] == 4095)
y_ok = (df[y_cols] >= y_min) & (df[y_cols] <= y_max) | (df[y_cols] == 4095)

# Rows where all x and y columns are okay
rows_ok = x_ok.all(axis=1) & y_ok.all(axis=1)

# Rows that are NOT ok
rows_out_of_range = df[~rows_ok]

print(rows_out_of_range)

```
All the stone coordinates are in range


```{python}
df.info()
```
```{python}
categorical_cols = [
    'competition_id',
    'end_id',
    'player_id',
    'task',
    'handle',
    'sheet',
    'lsfe',
    'winner',
    'powerplay',
    'timeout',
    'points',
    'noc',
    'venue'
]


for col in categorical_cols:
    freq_table = df[col].value_counts(dropna=False).reset_index()
    freq_table.columns = [col, 'Frequency']
    freq_table['Percentage'] = (freq_table['Frequency'] / freq_table['Frequency'].sum() * 100).round(2)
    
    print(f"Frequency table for {col}:\n", freq_table, "\n")
```
```{python}
df_invalid_player = df[(df["player_id"] == 3)][["match_id","end_id"]]
print("player_id = 3:")
print(df_invalid_player)
print("---------------------")
df_invalid_points = df[(df["points"] > 4)][["match_id","end_id"]]
print("points > 4:")
print(df_invalid_points)
```
```{python}
match_id_to_view = '22230015_48_1'
df_match = df[df["match_id"] == match_id_to_view]
df_match = df_match.sort_values(by='shot_id')
count = 0
for (mid, eid), game in df_match.groupby(['match_id', 'end_id']):
    print(f"Match {mid}, End {eid}")
    print(game[["team_id","player_id","shot_id"]])
    print("-" * 50)
    count += 1
    if count >= 10:
        break
```
```{python}
match_id_to_view = '0_9_2'
df_match = df[df["match_id"] == match_id_to_view]
df_match = df_match.sort_values(by='shot_id')
count = 0
for (mid, eid), game in df_match.groupby(['match_id', 'end_id']):
    print(f"Match {mid}, End {eid}")
    print(game[["team_id","points","result","task","shot_id"]])
    print("-" * 50)
    count += 1
    if count >= 10:
        break
```

EXPLORATION

We will explore the different types of shots
"0": "Draw"
"1": "Front"
"2": "Guard"
"3": "Raise / Tap-back"
"4": "Wick / Soft Peeling"
"5": "Freeze"
"6": "Take-out"
"7": "Hit and Roll"
"8": "Clearing"
"9": "Double Take-out"
"10": "Promotion Take-out"
"11": "through"
"13": "no statistics"
```{python}
freq_table = df['task'].value_counts().reset_index()
freq_table.columns = ['Task', 'Frequency']
freq_table['Percentage'] = (freq_table['Frequency'] / freq_table['Frequency'].sum() * 100).round(2)
print(freq_table)
bars = plt.bar(freq_table['Task'].astype(str), freq_table['Frequency'], color='skyblue')
plt.title('Frequency of Task Values')
plt.xlabel('Task')
plt.ylabel('Frequency')
```

Draw is the most common shot by far.
Freeze and Through are the least common.

How often players perfectly execute their shot?
```{python}
freq_table = df['points'].value_counts().reset_index()
freq_table.columns = ['Point', 'Frequency']
freq_table['Percentage'] = (freq_table['Frequency'] / freq_table['Frequency'].sum() * 100).round(2)
print(freq_table)
bars = plt.bar(freq_table['Point'].astype(str), freq_table['Frequency'], color='skyblue')
plt.title('Frequency of Point Values')
plt.xlabel('Point')
plt.ylabel('Frequency')
```

Logistic Regression
Outcome Variable: Steal
```{python}
df_non_hammer = df[df['hammer'] == 0].copy()
end_df= df_non_hammer.groupby(['match_id', 'end_id', 'team_id']).agg({
    'result': 'first',   # points scored by this team in the end
    'hammer': 'first',  # which team had the hammer

}).reset_index()

end_df['steal'] = ((end_df['result'] > 0) & (end_df['hammer'] == 0)).astype(int)

if 'steal' in df_non_hammer.columns:
    df_non_hammer = df_non_hammer.drop(columns=['steal'])

df_non_hammer = df_non_hammer.merge(
    end_df[['match_id', 'end_id', 'team_id','steal']],
    on=['match_id', 'end_id', 'team_id'],
    how='left'
)

```

```{python}
freq_table = df['end_id'].value_counts().reset_index()
freq_table.columns = ['end_id', 'Frequency']
freq_table['Percentage'] = (freq_table['Frequency'] / freq_table['Frequency'].sum() * 100).round(2)
print(freq_table)
bars = plt.bar(freq_table['end_id'].astype(str), freq_table['Frequency'], color='skyblue')
plt.title('Frequency of end_id Values')
plt.xlabel('end_id')
plt.ylabel('Frequency')

```
```{python}
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Your average results (already aggregated)
avg_results = df.groupby(['end_id','hammer'])['result'].mean().reset_index()

ends = sorted(avg_results['end_id'].unique())
width = 0.35

fig, ax = plt.subplots(figsize=(10,6), layout='constrained')

# Plot bars for each hammer value
for i, hammer_val in enumerate([1,0]):  # 1=Hammer, 0=Non-Hammer
    hammer_data = avg_results[avg_results['hammer']==hammer_val]
    # Align bars by offset
    offset = (i - 0.5) * width  # i=0 -> left, i=1 -> right
    ax.bar(hammer_data['end_id'] + offset, hammer_data['result'], width, 
           label='Hammer' if hammer_val==1 else 'Non-Hammer')

ax.set_xlabel('End ID')
ax.set_ylabel('Average Result')
ax.set_title('Average Result per End: Hammer vs Non-Hammer')
ax.set_xticks(ends)
ax.legend()
plt.show()
```
```{python}
results = sorted(df['result'].unique())

# Compute frequencies
hammer_counts = df[df['hammer']==1]['result'].value_counts().reindex(results, fill_value=0)
nonhammer_counts = df[df['hammer']==0]['result'].value_counts().reindex(results, fill_value=0)

x = np.arange(len(results))

# Plot stacked bars
fig, ax = plt.subplots(figsize=(8,6))
ax.bar(x, hammer_counts, label='Hammer', color='blue')
ax.bar(x, nonhammer_counts, bottom=hammer_counts, label='Non-Hammer', color='orange')

ax.set_xticks(x)
ax.set_xticklabels(results)
ax.set_xlabel('Result')
ax.set_ylabel('Frequency')
ax.set_title('Stacked Frequency of Results by Hammer vs Non-Hammer')
ax.legend()
plt.show()
```
```{python}
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Task code to label mapping
task_labels = {
    0: "Draw",
    1: "Front",
    2: "Guard",
    3: "Raise / Tap-back",
    4: "Wick / Soft Peeling",
    5: "Freeze",
    6: "Take-out",
    7: "Hit and Roll",
    8: "Clearing",
    9: "Double Take-out",
    10: "Promotion Take-out",
    11: "Through",
    13: "No Statistics"
}

# Map selected tasks to labels; everything else will become 'Other'
selected_tasks = [0, 1,2,6, 8,]  # your chosen subset
df['task_grouped'] = df['task'].where(df['task'].isin(selected_tasks), 'Other')
df['task_label'] = df['task_grouped'].map(task_labels)
df['task_label'] = df['task_label'].fillna('Other')  # ensure 'Other' exists

# Function to compute percent table per hammer value
def get_percent_table(df_subset, task_order):
    freq = df_subset.groupby(['end_id','task_label']).size().unstack(fill_value=0)
    freq_percent = freq.div(freq.sum(axis=1), axis=0) * 100
    # order columns safely
    column_order = [t for t in task_order if t in freq_percent.columns] + ['Other']
    freq_percent = freq_percent[column_order]
    return freq_percent

# Define task order for plotting
task_order = [task_labels[i] for i in selected_tasks]

# Separate for hammer and non-hammer
hammer_df = get_percent_table(df[df['hammer']==1], task_order)
nonhammer_df = get_percent_table(df[df['hammer']==0], task_order)

# Plot Hammer heatmap
plt.figure(figsize=(12,6))
sns.heatmap(hammer_df, annot=True, fmt='.1f', cmap='Blues', cbar_kws={'label':'Percent'})
plt.xlabel('Shot Type')
plt.ylabel('End ID')
plt.title('Percent of Shot Types per End - Hammer')
plt.show()

# Plot Non-Hammer heatmap
plt.figure(figsize=(12,6))
sns.heatmap(nonhammer_df, annot=True, fmt='.1f', cmap='Oranges', cbar_kws={'label':'Percent'})
plt.xlabel('Shot Type')
plt.ylabel('End ID')
plt.title('Percent of Shot Types per End - Non-Hammer')
plt.show()

```

```{python}
group_cols = ['match_id', 'end_id']
shots_per_group = df.groupby(group_cols)['shot_id'].count().reset_index()
shots_per_group.rename(columns={'shot_id': 'num_shots'}, inplace=True)

print(shots_per_group.head())
print(shots_per_group['num_shots'].describe())
shots_per_team = df.groupby(['match_id','end_id']).size().reset_index(name='num_shots')

# Filter rows with less than 5 shots
short_ends = shots_per_team[shots_per_team['num_shots'] < 10]

# Display the count and the rows
print(f"Number of ends with less than 10 shots: {len(short_ends)}")
print(short_ends)
```

```{python}
df['steal'] = np.where(df['hammer'] == 0, (df['result'] > 0).astype(int), np.nan)
freq_table = df['steal'].value_counts().reset_index()
freq_table.columns = ['steal', 'Frequency']
freq_table['Percentage'] = (freq_table['Frequency'] / freq_table['Frequency'].sum() * 100).round(2)
print(freq_table)
bars = plt.bar(freq_table['steal'].astype(str), freq_table['Frequency'], color='skyblue')
plt.title('Frequency of steal Values')
plt.xlabel('Non Hammer Steal')
plt.ylabel('Frequency')

```
```{python}
# Only non-hammer ends
non_hammer_ends = df[df['hammer'] == 0]

# Group by team
team_agg = non_hammer_ends.groupby(['team_id','competition_id'])['steal'].agg(
    steal_rate='mean',       # fraction of ends stolen
    total_ends='count',      # number of ends
    steals='sum'             # total steals
).reset_index()
team_agg_sorted = team_agg.sort_values(by='steal_rate', ascending=False).reset_index(drop=True)
print(team_agg_sorted.head(10))
```


```{python}
df_end_all = df.groupby(['match_id','end_id','team_id']).agg({
    'result':'first',
    'hammer':'first',
    'powerplay':'first',
    'steal':'first',

}).reset_index()

```
```{python}
import pandas as pd
import numpy as np

# --- Sheet constants ---
button_x, button_y = 750, 800
centerline_x = 750
tee_line_y = 800
hogline_y = 2900
backline_y = 200

house_radii = {
    'house_12': 1829,
    'house_8': 1219,
    'house_4': 610,
}

all_new_cols = {}

for i in range(1, 13):

    x = df[f'stone_{i}_x']
    y = df[f'stone_{i}_y']

    # --- Stone thrown? --- (0 means not thrown)
    thrown = ((x != 0) & (y != 0))

    # --- Distance to button (set to NaN if not thrown) ---
    all_new_cols[f'stone{i}_dist'] = np.where(
        thrown,
        np.sqrt((x - button_x)**2 + (y - button_y)**2),
        np.nan
    )

    # --- Off sheet ---
    all_new_cols[f'stone{i}_off'] = np.where(
        thrown,
        ((x == 4095) | (y == 4095)).astype(int),
        0
    )

    # --- In-house flags ---
    for name, radius in house_radii.items():
        all_new_cols[f'stone{i}_in_{name}'] = np.where(
            thrown,
            (all_new_cols[f'stone{i}_dist'] <= radius).astype(int),
            0
        )

    # --- Left/right of centerline ---
    all_new_cols[f'stone{i}_left'] = np.where(thrown, (x < centerline_x).astype(int), 0)
    all_new_cols[f'stone{i}_right'] = np.where(thrown, (x > centerline_x).astype(int), 0)

    # --- Above / below tee line ---
    all_new_cols[f'stone{i}_above_tee'] = np.where(thrown, (y < tee_line_y).astype(int), 0)
    all_new_cols[f'stone{i}_below_tee'] = np.where(thrown, (y > tee_line_y).astype(int), 0)

    # --- In-play (between backline & hogline) ---
    all_new_cols[f'stone{i}_in_play'] = np.where(
        thrown,
        ((y < hogline_y) & (y > backline_y)).astype(int),
        0
    )

    # --- Distance from centerline (traffic measure) ---
    all_new_cols[f'stone{i}_centerline_dist'] = np.where(thrown, np.abs(x - centerline_x), np.nan)

# --- Add all stone-level columns at once ---
df = pd.concat([df, pd.DataFrame(all_new_cols, index=df.index)], axis=1)
```

```{python}
import pandas as pd

# Boolean columns to sum
bool_cols = ['off','in_play','in_house_12','in_house_8','in_house_4',
             'left','right','above_tee','below_tee']

# Team 1: stones 1–6, Team 2: stones 7–12
team1_stones = range(1,7)
team2_stones = range(7,13)

def sum_bool_cols(df, stones, prefix):
    """Sum all bool columns for specified stones"""
    out = {}
    for col in bool_cols:
        cols_to_sum = [f'stone{i}_{col}' for i in stones if f'stone{i}_{col}' in df.columns]
        out[f'{prefix}_{col}'] = df[cols_to_sum].sum(axis=1).sum()
    return out

# Aggregate per end
df_ends = df.groupby(['match_id','end_id']).apply(
    lambda x: pd.Series({
        'team1_id': x['team_id1'].iloc[0],
        'team2_id': x['team_id2'].iloc[0],
        **sum_bool_cols(x, team1_stones, 'team1'),
        **sum_bool_cols(x, team2_stones, 'team2')
    })
).reset_index()
df_end_all = df_end_all.merge(
    df_ends,
    on=['match_id', 'end_id'],
    how='left'   # keeps all rows from df_end_all
)
```
```{python}
df_end_all = df_end_all.sort_values(['match_id','team_id','end_id'])
df_end_all['prev_result'] = df_end_all.groupby(['team_id','match_id'])['result'].shift(1).fillna(0)
df_end_all['prev_hammer'] = df_end_all.groupby(['team_id','match_id'])['hammer'].shift(1).fillna(0)

df_shot_stats = df.groupby(['match_id','end_id','team_id']).agg({
    'task': lambda x: x.mode()[0] if len(x) > 0 else -1,   # most common shot type
    'points': 'mean',  # average points per stone
}).reset_index()
# Sort and cumulative score per team

df_end_all['cum_score'] = df_end_all.groupby(['match_id','team_id'])['result'].cumsum()

# Merge opponent cumulative score
df_opponent = df_end_all[['match_id','end_id','team_id','cum_score']].rename(
    columns={'team_id':'hammer_team','cum_score':'hammer_cum_score'}
)
df_end_all = df_end_all.merge(df_opponent, on=['match_id','end_id'], how='left')
df_end_all = df_end_all[df_end_all['team_id'] != df_end_all['hammer_team']]

# Score differential from non-hammer perspective
df_end_all['score_diff'] = np.where(
    df_end_all['hammer'] == 0,
    df_end_all['cum_score'] - df_end_all['hammer_cum_score'],
    df_end_all['hammer_cum_score'] - df_end_all['cum_score']
)

df_end_all.head(16)

```

```{python}
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegressionCV
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.pipeline import Pipeline

# Filter non-hammer rows
df_model = df_end_all[df_end_all['hammer'] == 0].copy()

# Rename columns for clarity
rename_dict = {
    'team1_off': 'non_hammer_off',
    'team1_in_play': 'non_hammer_in_play',
    'team1_in_house_12': 'non_hammer_in_house_12',
    'team1_in_house_8': 'non_hammer_in_house_8',
    'team1_in_house_4': 'non_hammer_in_house_4',
    'team1_left': 'non_hammer_left',
    'team1_right': 'non_hammer_right',
    'team1_above_tee': 'non_hammer_above_tee',
    'team1_below_tee': 'non_hammer_below_tee',
    'team2_off': 'hammer_off',
    'team2_in_play': 'hammer_in_play',
    'team2_in_house_12': 'hammer_in_house_12',
    'team2_in_house_8': 'hammer_in_house_8',
    'team2_in_house_4': 'hammer_in_house_4',
    'team2_left': 'hammer_left',
    'team2_right': 'hammer_right',
    'team2_above_tee': 'hammer_above_tee',
    'team2_below_tee': 'hammer_below_tee'
}
df_model.rename(columns=rename_dict, inplace=True)

# Define target and features
target = 'steal'
feature_cols = [
    'non_hammer_off', 'non_hammer_in_play', 'non_hammer_in_house_12',
    'non_hammer_in_house_8', 'non_hammer_in_house_4', 'non_hammer_left',
    'non_hammer_right', 'non_hammer_above_tee', 'non_hammer_below_tee',
    'hammer_off', 'hammer_in_play', 'hammer_in_house_12',
    'hammer_in_house_8', 'hammer_in_house_4', 'hammer_left',
    'hammer_right', 'hammer_above_tee', 'hammer_below_tee',
    'powerplay', 'prev_result', 'prev_hammer','score_diff'
]

X = df_model[feature_cols]
y = df_model[target]

# Handle missing target values
X = X[y.notna()]
y = y[y.notna()]

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Pipeline with scaling + L1 logistic regression (auto-lasso)
pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("model", LogisticRegressionCV(
        Cs=20,
        penalty="l1",
        solver="saga",
        cv=5,
        scoring="roc_auc",
        max_iter=5000,
        n_jobs=-1,
        class_weight='balanced'
    ))
])

pipeline.fit(X_train, y_train)

# Predict & evaluate
y_pred = pipeline.predict(X_test)
y_proba = pipeline.predict_proba(X_test)[:,1]

print("Classification Report:\n", classification_report(y_test, y_pred))
print("ROC AUC Score:", roc_auc_score(y_test, y_proba))

# Get important coefficients
coef_df = pd.DataFrame({
    'feature': feature_cols,
    'coefficient': pipeline.named_steps['model'].coef_[0],
    'abs_coefficient': abs(pipeline.named_steps['model'].coef_[0])
}).sort_values('abs_coefficient', ascending=False)

print(coef_df)

```

